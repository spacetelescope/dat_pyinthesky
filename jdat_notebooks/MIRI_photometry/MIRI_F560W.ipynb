{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "insured-dominican",
   "metadata": {},
   "source": [
    "# MIRI PSF Photometry #1 - F560W PSF Photometry\n",
    "\n",
    "**Author**: Ori Fox\n",
    "<br>\n",
    "**Last Updated**: March, 2022"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "precious-determination",
   "metadata": {},
   "source": [
    "## Table of contents\n",
    "1. [Introduction](#intro)<br>\n",
    "2. [Setup](#setup)<br>\n",
    "    2.1 [Python imports](#py_imports)<br>\n",
    "    2.2 [Plotting functions imports](#matpl_imports)<br>\n",
    "    2.3 [PSF FWHM dictionary](#psf_fwhm)<br>\n",
    "3. [Import image to analyze](#data)<br>\n",
    "    3.1 [Display image](#display_data)<br>\n",
    "    3.2 [Convert image units and apply pixel area map](#convert_data)<br>\n",
    "4. [Create a synthetic PSF model (with WebbPSF)](#webbpsf_intro)<br>\n",
    "    4.1 [Create the single PSF](#single_webbpsf)<br>\n",
    "    4.2 [Display the single PSF](#display_single_webbpsf)<br>\n",
    "    4.3 [Create the grid of PSFs](#grid_webbpsf)<br>\n",
    "    4.4 [Display the grid of PSFs](#display_grid_webbpsf)<br>\n",
    "5. [Create the PSF model building an effective PSF](#epsf_intro)<br>\n",
    "    5.1 [Calculate the background](#bkg)<br>\n",
    "    5.2 [Find sources in the image](#find)<br>\n",
    "    5.3 [Select sources](#select)<br>\n",
    "    5.4 [Create catalog of selected sources](#create_cat)<br>\n",
    "    5.5 [Build the effective PSF](#build_epsf)<br>\n",
    "    5.6 [Display the effective PSF](#display_epsf)<br>\n",
    "6. [Perform PSF Photometry](#psf_phot)<br>\n",
    "    6.1 [PSF photometry output catalog](#psf_cat)<br>\n",
    "    6.2 [Display residual images](#residual)<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "valid-brazilian",
   "metadata": {},
   "source": [
    "1.<font color='white'>-</font>Introduction <a class=\"anchor\" id=\"intro\"></a>\n",
    "------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "north-blowing",
   "metadata": {},
   "source": [
    "**Data**: MIRI simulated images obtained using [MIRISIM](https://www.stsci.edu/jwst/science-planning/proposal-planning-toolbox/mirisim) and run through the [JWST pipeline](https://jwst-pipeline.readthedocs.io/en/latest/) of Isochrone of 10-Gyr old population, [Fe/H]=-1 Population placed at 2.5 kpc from the Sun. Salpeter-like IMF, tweaked to have more massive stars (since positions are random, it ensures at least a few bright stars in each image). Kept only sources brighter than J=17 (random cut to speed up MIRISim) and fainter than Ks=10 (to avoid too-bright stars that would have PSF spikes clearly cut by MIRISim in the image)\n",
    "\n",
    "Here is the [ReadMe](https://stsci.app.box.com/s/2b6evrie2swaybarxhdmpqizktl3g0wm/file/869444882607). All data simulations can be found on [STScI's simulation page](https://www.stsci.edu/jwst/science-planning/proposal-planning-toolbox/simulated-data).\n",
    "\n",
    "PSF Photometry can be obtained using:\n",
    "\n",
    "* single PSF model obtained from WebbPSF\n",
    "* grid of PSF models from WebbPSF\n",
    "* single effective PSF (ePSF)\n",
    "* grid of effective PSF (bonus part II)\n",
    "\n",
    "The notebook shows:\n",
    "\n",
    "* how to obtain the PSF model from WebbPSF (or build an ePSF)\n",
    "* how to perform PSF photometry on the image\n",
    "* how to cross-match the catalogs of the different images (bonus part I)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "experienced-killing",
   "metadata": {},
   "source": [
    "2.<font color='white'>-</font>Setup <a class=\"anchor\" id=\"setup\"></a>\n",
    "------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "registered-momentum",
   "metadata": {},
   "source": [
    "In this section we import all the necessary python packages and we define some plotting parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intimate-budget",
   "metadata": {},
   "source": [
    "### 2.1<font color='white'>-</font>Python imports<a class=\"anchor\" id=\"py_imports\"></a> ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "necessary-science",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "if not os.environ.get('WEBBPSF_PATH'):\n",
    "    os.environ['WEBBPSF_PATH'] = '/data/webbpsf-data'\n",
    "\n",
    "import sys\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import glob as glob\n",
    "\n",
    "import urllib.request\n",
    "\n",
    "import tarfile\n",
    "\n",
    "from astropy.io import fits\n",
    "from astropy.visualization import simple_norm\n",
    "from astropy.nddata import NDData\n",
    "from astropy.modeling.fitting import LevMarLSQFitter\n",
    "from astropy.table import Table, QTable\n",
    "from astropy.coordinates import SkyCoord, match_coordinates_sky\n",
    "from astropy import units as u\n",
    "\n",
    "from photutils.background import MMMBackground, MADStdBackgroundRMS, Background2D\n",
    "from photutils.detection import DAOStarFinder\n",
    "from photutils import EPSFBuilder, GriddedPSFModel\n",
    "from photutils.psf import DAOGroup, extract_stars, IterativelySubtractedPSFPhotometry\n",
    "\n",
    "import jwst\n",
    "from jwst.datamodels import ImageModel\n",
    "\n",
    "import webbpsf\n",
    "from webbpsf.utils import to_griddedpsfmodel\n",
    "\n",
    "import pysynphot  # PYSIN_CDBS must be defined in the user's environment (see note below)\n",
    "\n",
    "from collections import OrderedDict\n",
    "from astropy.wcs import WCS\n",
    "\n",
    "from jdaviz import Imviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "hundred-ceramic",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:py.warnings:/var/folders/yh/kl4y3s1x3_j3ywy3qq67g3vc0001kc/T/ipykernel_62204/2969300567.py:51: DeprecationWarning: Importing display from IPython.core.display is deprecated since IPython 7.14, please import from IPython display\n",
      "  from IPython.core.display import display, HTML\n",
      "\n",
      "2022-04-11 09:43:24,154 - stpipe - WARNING - /var/folders/yh/kl4y3s1x3_j3ywy3qq67g3vc0001kc/T/ipykernel_62204/2969300567.py:51: DeprecationWarning: Importing display from IPython.core.display is deprecated since IPython 7.14, please import from IPython display\n",
      "  from IPython.core.display import display, HTML\n",
      "\n",
      "WARNING:stpipe:/var/folders/yh/kl4y3s1x3_j3ywy3qq67g3vc0001kc/T/ipykernel_62204/2969300567.py:51: DeprecationWarning: Importing display from IPython.core.display is deprecated since IPython 7.14, please import from IPython display\n",
      "  from IPython.core.display import display, HTML\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>.container { width:90% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#\n",
    "# General tools\n",
    "#\n",
    "import glob\n",
    "import os\n",
    "import shutil\n",
    "import sys\n",
    "import random\n",
    "import urllib\n",
    "import zipfile\n",
    "#\n",
    "# Astropy tools\n",
    "#\n",
    "from astropy.coordinates import match_coordinates_sky, SkyCoord\n",
    "from astropy.io import fits, ascii\n",
    "from astropy.stats import SigmaClip, sigma_clipped_stats\n",
    "from astropy.table import Table, Column, vstack\n",
    "import astropy.units as u\n",
    "from astropy.visualization import LogStretch, LinearStretch, PercentileInterval, ManualInterval\n",
    "from astropy.nddata import Cutout2D\n",
    "#\n",
    "# JWST models\n",
    "#\n",
    "from jwst import datamodels, associations\n",
    "from jwst.datamodels import ImageModel, dqflags\n",
    "#\n",
    "# Matplotlib tools\n",
    "#\n",
    "from matplotlib import style, pyplot as plt, rcParams\n",
    "from matplotlib.colors import LogNorm\n",
    "from matplotlib.pyplot import figure\n",
    "from mpl_toolkits.axes_grid1.axes_divider import make_axes_locatable\n",
    "#\n",
    "# Numpy library\n",
    "#\n",
    "import numpy as np\n",
    "#\n",
    "# Photutils library and tools\n",
    "#\n",
    "import photutils\n",
    "from photutils.aperture import CircularAperture, CircularAnnulus, aperture_photometry\n",
    "from photutils import Background2D, MedianBackground, ModeEstimatorBackground, MMMBackground\n",
    "#\n",
    "# Scipy tools\n",
    "#\n",
    "from scipy import stats\n",
    "from scipy.interpolate import CubicSpline\n",
    "#\n",
    "# Use 90% of the window width\n",
    "#\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:90% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spread-concord",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "**Note on pysynphot**: Data files for pysynphot are distributed separately by Calibration Reference Data System. They are expected to follow a certain directory structure under the root directory, identified by the PYSYN_CDBS environment variable that must be set prior to using this package. In the example below, the root directory is arbitrarily named /my/local/dir/trds/. \\\n",
    "export PYSYN_CDBS=/my/local/dir/trds/ \\\n",
    "See documentation [here](https://pysynphot.readthedocs.io/en/latest/#installation-and-setup) for the configuration and download of the data files.\n",
    "    \n",
    "<div >"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "organized-favorite",
   "metadata": {},
   "source": [
    "### 2.2<font color='white'>-</font>Plotting function imports<a class=\"anchor\" id=\"matpl_imports\"></a> ###"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "worst-badge",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "    <h3><u><b>Warning</b></u></h3>\n",
    "\n",
    "If the plots in this notebook don't render properly, you may need to install LaTeX. Find more information on a system-wide installation [here](https://www.latex-project.org/get/) and on a Jupyter-specific nbextension [here](https://jupyter-contrib-nbextensions.readthedocs.io/en/latest/nbextensions/latex_envs/README.html).\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "optional-consciousness",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import style, pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "plt.rcParams['image.cmap'] = 'viridis'\n",
    "plt.rcParams['image.origin'] = 'lower'\n",
    "plt.rcParams['axes.titlesize'] = plt.rcParams['axes.labelsize'] = 30\n",
    "plt.rcParams['xtick.labelsize'] = plt.rcParams['ytick.labelsize'] = 20\n",
    "\n",
    "font1 = {'family': 'helvetica', 'color': 'black', 'weight': 'normal', 'size': '12'}\n",
    "font2 = {'family': 'helvetica', 'color': 'black', 'weight': 'normal', 'size': '20'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "comparative-geometry",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "# Figure size\n",
    "plt.rcParams['figure.figsize'] = [15, 15]\n",
    "# Figure text and font\n",
    "plt.rc('text', usetex=True)\n",
    "plt.rc('font', size=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "friendly-stamp",
   "metadata": {},
   "source": [
    "### 2.3<font color='white'>-</font>PSF FWHM dictionary<a class=\"anchor\" id=\"psf_fwhm\"></a> ###"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acquired-responsibility",
   "metadata": {},
   "source": [
    "The dictionary contains the NIRCam point spread function (PSF) FWHM, from the [NIRCam Point Spread Function](https://jwst-docs.stsci.edu/near-infrared-camera/nircam-predicted-performance/nircam-point-spread-functions) JDox page. The FWHM are calculated from the analysis of the expected NIRCam PSFs simulated with [WebbPSF](https://www.stsci.edu/jwst/science-planning/proposal-planning-toolbox/psf-simulation-tool). \n",
    "\n",
    "**Note**: this dictionary will be updated once the values for the FWHM will be available for each detectors after commissioning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "intimate-fault",
   "metadata": {},
   "outputs": [],
   "source": [
    "filters = ['F560W', 'F770W', 'F1000W', 'F1130W', 'F1280W', 'F1500W', 'F1800W', 'F2100W', 'F2550W']\n",
    "\n",
    "psf_fwhm = [1.636, 2.187, 2.888, 3.318, 3.713, 4.354, 5.224, 5.989, 7.312] #pixls\n",
    "\n",
    "dict_utils = {filters[i]: {'psf fwhm': psf_fwhm[i]} for i in range(len(filters))}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "registered-disclaimer",
   "metadata": {},
   "source": [
    "### 2.4 Useful Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "functional-psychiatry",
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow_me_wcolorbar(img, vmin, vmax, tlabel, xlabel, ylabel, blabel, cmap):\n",
    "    '''\n",
    "    Function to show an image.\n",
    "    \n",
    "    Inputs\n",
    "    ----------\n",
    "    img : 2D numpy.ndarray\n",
    "        The input 2D array.\n",
    "    vmin : float\n",
    "        The minimum value for the colorbar.\n",
    "    vmax : float\n",
    "        The maximum value for the colorbar.\n",
    "    tlabel : string\n",
    "        The plot title.\n",
    "    xlabel : string\n",
    "        The X-axis label.\n",
    "    ylabel : string\n",
    "        The Y-axis label.\n",
    "    blabel : string\n",
    "        The colorbar label.\n",
    "    cmap : string\n",
    "        The name of the colormap.\n",
    "    '''\n",
    "    \n",
    "    fig, ax = plt.subplots()\n",
    "    cax = ax.imshow(img, vmin=vmin, vmax=vmax, origin='lower', cmap=cmap)\n",
    "    ax_divider = make_axes_locatable(ax)\n",
    "    cax1 = ax_divider.append_axes('right', size='3%', pad='2%')\n",
    "    cb = fig.colorbar(cax, cax=cax1)\n",
    "    cb.ax.set_ylabel(r'{0}'.format(blabel))\n",
    "    ax.set_xlabel(r'{0}'.format(xlabel))\n",
    "    ax.set_ylabel(r'{0}'.format(ylabel))\n",
    "    ax.set_title(r'{0}'.format(tlabel))\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "detailed-foster",
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow_me_wcolorbar_setup(img, vmin, vmax, tlabel, xlabel, ylabel, blabel, cmap):\n",
    "    '''\n",
    "    Function to setup an image to show. Similar to imshow_me_wcolorbar,\n",
    "    but it does not show the image directly, thus allowing to plot\n",
    "    something else after the call.\n",
    "    \n",
    "    Inputs\n",
    "    ----------\n",
    "    img : 2D numpy.ndarray\n",
    "        The input 2D array.\n",
    "    vmin : float\n",
    "        The minimum value for the colorbar.\n",
    "    vmax : float\n",
    "        The maximum value for the colorbar.\n",
    "    tlabel : string\n",
    "        The plot title.\n",
    "    xlabel : string\n",
    "        The X-axis label.\n",
    "    ylabel : string\n",
    "        The Y-axis label.\n",
    "    blabel : string\n",
    "        The colorbar label.\n",
    "    cmap : string\n",
    "        The name of the colormap.\n",
    "    '''\n",
    "    \n",
    "    cax = ax.imshow(img, vmin=vmin, vmax=vmax, origin='lower', cmap=cmap)\n",
    "    ax_divider = make_axes_locatable(ax)\n",
    "    cax1 = ax_divider.append_axes('right', size='3%', pad='2%')\n",
    "    cb = fig.colorbar(cax, cax=cax1)\n",
    "    cb.ax.set_ylabel(r'{0}'.format(blabel))\n",
    "    ax.set_xlabel(r'{0}'.format(xlabel))\n",
    "    ax.set_ylabel(r'{0}'.format(ylabel))\n",
    "    ax.set_title(r'{0}'.format(tlabel))\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "charged-wales",
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow_cutouts(img, tab, id_sel, xlabel, ylabel, cmap):\n",
    "    '''\n",
    "    Function to show four cutouts from an image.\n",
    "    \n",
    "    Inputs\n",
    "    ----------\n",
    "    img : 2D numpy.ndarray\n",
    "        The input 2D array.\n",
    "    tab : Table\n",
    "        The table with at least (x,y,id) columns.\n",
    "    id_sel : array(int)\n",
    "        The ID of the sources in tab to show in the cutouts.\n",
    "    xlabel : string\n",
    "        The X-axis label.\n",
    "    ylabel : string\n",
    "        The Y-axis label.\n",
    "    cmap : string\n",
    "        The name of the colormap.\n",
    "    '''\n",
    "    \n",
    "    fig, ax = plt.subplots(2, 2)\n",
    "\n",
    "    x, y = tab['x'][tab['id'] == id_sel[0]], tab['y'][tab['id'] == id_sel[0]]\n",
    "    cutout = Cutout2D(img, (x, y), (51, 51))\n",
    "    ax[0, 0].imshow(cutout.data, vmin=-0.1, vmax=1.0, origin='lower', cmap=cmap)\n",
    "    ax[0, 0].scatter(cutout.input_position_cutout[0], cutout.input_position_cutout[1], lw=0.5, s=15, \n",
    "                     marker='o', edgecolors='deepskyblue', facecolors='none')\n",
    "    ax[0, 0].annotate(r'(x,y)$\\sim$({0},{1})'.format(int(x[0]), int(y[0])), xy=(0.5, 0.95), xycoords='axes fraction',\n",
    "                      horizontalalignment='center', verticalalignment='center')\n",
    "    ax[0, 0].set_xlabel(r'{0}'.format(xlabel))\n",
    "    ax[0, 0].set_ylabel(r'{0}'.format(ylabel))\n",
    "\n",
    "    x, y = tab['x'][tab['id'] == id_sel[1]], tab['y'][tab['id'] == id_sel[1]]\n",
    "    cutout = Cutout2D(img, (x, y), (51, 51))\n",
    "    ax[0, 1].imshow(cutout.data, vmin=-0.1, vmax=1.0, origin='lower', cmap=cmap)\n",
    "    ax[0, 1].scatter(cutout.input_position_cutout[0], cutout.input_position_cutout[1], lw=0.5, s=15, \n",
    "                     marker='o', edgecolors='deepskyblue', facecolors='none')\n",
    "    ax[0, 1].annotate(r'(x,y)$\\sim$({0},{1})'.format(int(x[0]), int(y[0])), xy=(0.5, 0.95), xycoords='axes fraction', \n",
    "                      horizontalalignment='center', verticalalignment='center')\n",
    "    ax[0, 1].set_xlabel(r'{0}'.format(xlabel))\n",
    "    ax[0, 1].set_ylabel(r'{0}'.format(ylabel))\n",
    "\n",
    "    x, y = tab['x'][tab['id'] == id_sel[2]], tab['y'][tab['id'] == id_sel[2]]\n",
    "    cutout = Cutout2D(img, (x, y), (51, 51))\n",
    "    ax[1, 0].imshow(cutout.data, vmin=-0.1, vmax=1.0, origin='lower', cmap=cmap)\n",
    "    ax[1, 0].scatter(cutout.input_position_cutout[0], cutout.input_position_cutout[1], lw=0.5, s=15, \n",
    "                     marker='o', edgecolors='deepskyblue', facecolors='none')\n",
    "    ax[1, 0].annotate(r'(x,y)$\\sim$({0},{1})'.format(int(x[0]), int(y[0])), xy=(0.5, 0.95), xycoords='axes fraction', \n",
    "                      horizontalalignment='center', verticalalignment='center')\n",
    "    ax[1, 0].set_xlabel(r'{0}'.format(xlabel))\n",
    "    ax[1, 0].set_ylabel(r'{0}'.format(ylabel))\n",
    "\n",
    "    x, y = tab['x'][tab['id'] == id_sel[3]], tab['y'][tab['id'] == id_sel[3]]\n",
    "    cutout = Cutout2D(img, (x, y), (51, 51))\n",
    "    ax[1, 1].imshow(cutout.data, vmin=-0.1, vmax=1.0, origin='lower', cmap=cmap)\n",
    "    ax[1, 1].scatter(cutout.input_position_cutout[0], cutout.input_position_cutout[1], lw=0.5, s=15, \n",
    "                     marker='o', edgecolors='deepskyblue', facecolors='none')\n",
    "    ax[1, 1].annotate(r'(x,y)$\\sim$({0},{1})'.format(int(x[0]), int(y[0])), xy=(0.5, 0.95), xycoords='axes fraction', \n",
    "                      horizontalalignment='center', verticalalignment='center')\n",
    "    ax[1, 1].set_xlabel(r'{0}'.format(xlabel))\n",
    "    ax[1, 1].set_ylabel(r'{0}'.format(ylabel))\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "weird-rouge",
   "metadata": {},
   "outputs": [],
   "source": [
    "def arcsec2pix(x):\n",
    "    '''\n",
    "    Function that converts arcsec in MIRIM pixels.\n",
    "    It is used to setup the secondary axes in a plot.\n",
    "    \n",
    "    Inputs\n",
    "    ----------\n",
    "    x : float or array(float)\n",
    "        The value in arcsec.\n",
    "        \n",
    "    Outputs\n",
    "    ----------\n",
    "    The value(s) in MIRIM pixel.\n",
    "    '''\n",
    "    \n",
    "    return x/0.11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "superb-bride",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pix2arcsec(x):\n",
    "    '''\n",
    "    Function that converts MIRIM pixels in arcsec.\n",
    "    It is used to setup the secondary axes in a plot.\n",
    "    \n",
    "    Inputs\n",
    "    ----------\n",
    "    x : float or array(float)\n",
    "        The value in MIRIM pixels.\n",
    "        \n",
    "    Outputs\n",
    "    ----------\n",
    "    The value(s) in arcsec.\n",
    "    '''\n",
    "    \n",
    "    return x*0.11"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "medieval-decision",
   "metadata": {},
   "source": [
    "These last three functions will be used to speed-up the exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "concrete-pension",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_image(img_name):\n",
    "    '''\n",
    "    Function that reads one image, flag all pixels with DQ flags different \n",
    "    from [0, 2, 4, 6] and adds a random background gradient.\n",
    "    To be used in the exercise.\n",
    "    \n",
    "    Inputs\n",
    "    ----------\n",
    "    img_name : string\n",
    "        The name of the image.\n",
    "        \n",
    "    Outputs\n",
    "    ----------\n",
    "    img : ImageModel\n",
    "        The data model of the image.\n",
    "    img_mod : 2D numpy.ndarray\n",
    "        The image data with the additional random background gradient.\n",
    "    '''\n",
    "    \n",
    "    img = datamodels.open(img_name)\n",
    "    ok = np.zeros(img.data.shape, dtype='int')\n",
    "    for v in [0, 2, 4, 6]:\n",
    "        ok = ok + np.where(img.dq == v, 1, 0)\n",
    "\n",
    "    img.data[ok == 0] = np.nan\n",
    "    \n",
    "    x = np.linspace(0, 1, img.meta.subarray.xsize)\n",
    "    y = np.linspace(0, 1, img.meta.subarray.ysize)\n",
    "    X, Y = np.meshgrid(x, y)\n",
    "    if (np.random.rand(1) > 0.5):\n",
    "        sx = +1\n",
    "    else:\n",
    "        sx = -1\n",
    "    if (np.random.rand(1) > 0.5):\n",
    "        sy = +1\n",
    "    else:\n",
    "        sy = -1\n",
    "    Z = (10*(np.random.rand(1)-0.5))*np.exp(sx*X/(4+2*(np.random.rand(1)-0.5)))*np.exp(sy*Y/(4+4*(np.random.rand(1)-0.5)))\n",
    "    \n",
    "    img_mod = img.data.copy() + Z\n",
    "    \n",
    "    _, sky_med, sky_sig = sigma_clipped_stats(img_mod[np.isfinite(img_mod)], sigma=5.0, maxiters=5)\n",
    "    \n",
    "    print('')\n",
    "    print(r' Suggested min value: {0}'.format(sky_med-sky_sig))\n",
    "    print(r' Suggested max value: {0}'.format(sky_med+sky_sig))\n",
    "    print('')\n",
    "\n",
    "    cmin = sky_med-sky_sig\n",
    "    cmax = sky_med+sky_sig\n",
    "    \n",
    "    return img, img_mod, cmin, cmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "statistical-dayton",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_table(img, xy_tmp, aperture_radius, sky, flux, rad_label):\n",
    "    '''\n",
    "    Function that performs additional steps discussed in the notebook.\n",
    "    To be used in the exercise.\n",
    "    \n",
    "    Inputs\n",
    "    ----------\n",
    "    img : ImageModel\n",
    "        The data model of the image.\n",
    "    xy_tmp : Table\n",
    "        The table created by DAOStarFinder with the sources detected\n",
    "        in the image.\n",
    "    aperture_radius : float\n",
    "        The aperture radius used for the aperture photometry.\n",
    "    sky : array(float)\n",
    "        The array with the local sky background for each source.\n",
    "    flux : array(float)\n",
    "        The array with the sky-subtracted flux for each source.\n",
    "    rad_label : string\n",
    "        The label for the photometry in the Table.\n",
    "        \n",
    "    Outputs\n",
    "    ----------\n",
    "    aperture_table : Table\n",
    "        The final astro-photometric table.\n",
    "    '''\n",
    "    \n",
    "    aperture_table = Table()\n",
    "\n",
    "    aperture_table['x'] = xy_tmp['xcentroid']\n",
    "    aperture_table['y'] = xy_tmp['ycentroid']\n",
    "    aperture_table['sharpness'] = xy_tmp['sharpness']\n",
    "    aperture_table['roundness1'] = xy_tmp['roundness1']\n",
    "    aperture_table['roundness2'] = xy_tmp['roundness2']\n",
    "\n",
    "    aperture_table['id'] = xy_tmp['id']\n",
    "    \n",
    "    aperture_table['local_sky_' + rad_label] = sky\n",
    "    aperture_table['aperture_' + rad_label + '_skysub'] = flux\n",
    "    \n",
    "    keep_good = np.logical_and(np.isfinite(aperture_table['aperture_' + rad_label + '_skysub']), \n",
    "                               aperture_table['aperture_' + rad_label + '_skysub'] > 0.)\n",
    "    aperture_table = aperture_table[keep_good]\n",
    "        \n",
    "    aperture_table['mag_' + rad_label] = -2.5*np.log10(aperture_table['aperture_' + rad_label + '_skysub'])\n",
    "\n",
    "    aperture_table['flag_' + rad_label] = np.zeros(len(aperture_table), dtype=int)\n",
    "    for s in aperture_table:\n",
    "        jmin = max(1, int(np.floor(s['y']-aperture_radius)))\n",
    "        jmax = min(round(s['y']+aperture_radius)+1, img.shape[0])\n",
    "        imin = max(1, int(np.floor(s['x']-aperture_radius)))\n",
    "        imax = min(round(s['x']+aperture_radius)+1, img.shape[1])\n",
    "        if (np.sum(img.dq[jmin:jmax, imin:imax] == 6) > 0):\n",
    "            s['flag_' + rad_label] = 6\n",
    "        elif (np.sum(img.dq[jmin:jmax, imin:imax] == 2) > 0):\n",
    "            s['flag_' + rad_label] = 2\n",
    "        elif (np.sum(img.dq[jmin:jmax, imin:imax] == 4) > 0):\n",
    "            s['flag_' + rad_label] = 4       \n",
    "\n",
    "    aperture_table['ra'] = aperture_table['x']\n",
    "    aperture_table['dec'] = aperture_table['y']\n",
    "    for a in aperture_table:\n",
    "        rd = img.meta.wcs.transform(\"detector\", \"world\", a['x'], a['y'])    \n",
    "        a['ra'] = rd[0]\n",
    "        if (a['ra'] > 180):\n",
    "            a['ra'] -= 360.0\n",
    "        a['dec'] = rd[1]\n",
    "        \n",
    "    return aperture_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "characteristic-ambassador",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_phot_cal(cat_name, tmp, sel_radius):\n",
    "    '''\n",
    "    Function that cross-matches two catalogs and plot the positional residuals.\n",
    "    To be used in the exercise.\n",
    "    \n",
    "    Inputs\n",
    "    ----------\n",
    "    cat_name : string\n",
    "        The name of the pipeline source catalog\n",
    "    tmp : Table\n",
    "        The astro-photometric table.\n",
    "    sel_radius : float\n",
    "        The radius for the positional-residual selection in arcsec.\n",
    "        \n",
    "    Outputs\n",
    "    ----------\n",
    "    calib_cat : Table\n",
    "        The pipeline source catalog.\n",
    "    ind_i2d_cat: array(int)\n",
    "        The array with the indexes from match_sky_coordinates.\n",
    "    dist_2d: array(float)\n",
    "        The array with the 2D distances from match_sky_coordinates.\n",
    "    '''\n",
    "    \n",
    "    calib_cat = Table.read(cat_name)\n",
    "\n",
    "    coord_cal = SkyCoord(ra=tmp['ra'], dec=tmp['dec'], unit=\"deg\")\n",
    "    coord_i2d = SkyCoord(ra=calib_cat['sky_centroid'].ra.degree, dec=calib_cat['sky_centroid'].dec.degree, unit=\"deg\")\n",
    "    ind_i2d_cat, dist_2d, a = match_coordinates_sky(coord_cal, coord_i2d)\n",
    "\n",
    "    delta_ra = 3600.0*(tmp['ra']*np.cos(np.deg2rad(tmp['dec'])) - \n",
    "                       calib_cat[ind_i2d_cat]['sky_centroid'].ra.degree * \n",
    "                       np.cos(np.deg2rad(calib_cat[ind_i2d_cat]['sky_centroid'].dec.degree)))\n",
    "\n",
    "    delta_dec = 3600.0*(tmp['dec']-calib_cat[ind_i2d_cat]['sky_centroid'].dec.degree)\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.scatter(delta_ra, delta_dec, lw=0.5, s=5, color='black', marker='o')\n",
    "    circle = plt.Circle((0, 0), sel_radius, color='r', fill=False)\n",
    "    ax.add_patch(circle)\n",
    "    ax.set_xlim(-0.5, 0.5)\n",
    "    ax.set_ylim(-0.5, 0.5)\n",
    "    ax.axhline(0, color='red', ls='--')\n",
    "    ax.axvline(0, color='red', ls='--')\n",
    "    ax.set_aspect('equal', 'box')\n",
    "    ax.set_xlabel(r'$\\Delta\\textrm{(R.A.}\\cos\\textrm{Dec.) [arcsec]}$')\n",
    "    ax.set_ylabel(r'$\\Delta\\textrm{Dec. [arcsec]}$')\n",
    "\n",
    "    ax2 = ax.secondary_xaxis('top', functions=(arcsec2pix, pix2arcsec))\n",
    "    ax2.set_xlabel(r'$\\Delta\\textrm{(R.A.}\\cos\\textrm{Dec.) [MIRIM pixel]}$')\n",
    "    ay2 = ax.secondary_yaxis('right', functions=(arcsec2pix, pix2arcsec))\n",
    "    ay2.set_ylabel(r'$\\Delta\\textrm{Dec. [MIRIM pixel]}$')\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    return calib_cat, ind_i2d_cat, dist_2d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "specialized-background",
   "metadata": {},
   "source": [
    "We adopted as Background estimator the function [MMMBackground](https://photutils.readthedocs.io/en/stable/api/photutils.background.MMMBackground.html#photutils.background.MMMBackground), which calculates the background in an array using the DAOPHOT MMM algorithm, on the whole image (The background is calculated using a mode estimator of the form `(3 * median) - (2 * mean)`). \n",
    "\n",
    "When dealing with a variable background and/or the need to mask the regions where we have no data (for example, if we are analyzing an image with all the 4 NIRCam SW detectors, i.e. containing the chip gaps), we can set `var_bkg = True` and use a more complex algorithm that takes into account those issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "unsigned-compilation",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_bkg(var_bkg=False):\n",
    "    \n",
    "    bkgrms = MADStdBackgroundRMS()\n",
    "    mmm_bkg = MMMBackground()\n",
    "    im = fits.open(dict_images[det][filt]['images'][0])\n",
    "\n",
    "    if var_bkg:\n",
    "        print('Using 2D Background')\n",
    "        sigma_clip = SigmaClip(sigma=3.0, maxiters=10)\n",
    "        #coverage_mask = (data == 0)\n",
    "        \n",
    "        # Mask all nan or inf pixels\n",
    "        coverage_mask = np.full(np.shape(im[1].data), False, dtype=bool)\n",
    "        coverage_mask[np.isnan(im[1].data)] = True\n",
    "        coverage_mask[~np.isfinite(im[1].data)] = True\n",
    "\n",
    "        bkg = Background2D(data, (20, 20), filter_size=(30, 30), sigma_clip=sigma_clip, bkg_estimator=mmm_bkg,\n",
    "                           coverage_mask=coverage_mask, fill_value=0.0)\n",
    "\n",
    "        data_bkgsub = data.copy()\n",
    "        data_bkgsub = data_bkgsub - bkg.background\n",
    "\n",
    "        #_, _, std = sigma_clipped_stats(data_bkgsub)\n",
    "        std = bkg.background_rms_median\n",
    "\n",
    "    else:\n",
    "\n",
    "        std = bkgrms(data)\n",
    "        bkg = mmm_bkg(data)\n",
    "\n",
    "        data_bkgsub = data.copy()\n",
    "        data_bkgsub -= bkg\n",
    "\n",
    "    return data_bkgsub, std"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prime-negative",
   "metadata": {},
   "source": [
    "3.<font color='white'>-</font>Import images to analyze<a class=\"anchor\" id=\"data\"></a>\n",
    "------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "valid-organic",
   "metadata": {},
   "source": [
    "We load all the images and we create a dictionary that contains all of them, divided by detectors and filters. This is useful to check which detectors and filters are available and to decide if we want to perform the photometry on all of them or only on a subset.\n",
    "\n",
    "We retrieve the MIRI detector and filter from the image header."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "automatic-memorabilia",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Images and catalogs should be already in './data/'. If not, delete the folder and run this cell again.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "folder_path = './data/'\n",
    "\n",
    "if (folder_path == './'):\n",
    "    print('')\n",
    "    print(' Please set another folder that is not the main folder.')\n",
    "    print('')\n",
    "    pass\n",
    "elif os.path.isdir(folder_path):\n",
    "    print('')\n",
    "    print(' Images and catalogs should be already in \\'' + folder_path + \n",
    "          '\\'. If not, delete the folder and run this cell again.')\n",
    "    print('')\n",
    "    pass\n",
    "elif (os.path.isfile('./stage2-selected.zip') and \n",
    "      os.path.isfile('./stage3-selected.zip')):\n",
    "    # Extract both zip files if they are present\n",
    "    boxfile = './stage2-selected.zip'\n",
    "    with zipfile.ZipFile(boxfile) as zf:\n",
    "        zf.extractall(folder_path)        \n",
    "    boxfile = './stage3-selected.zip'\n",
    "    with zipfile.ZipFile(boxfile) as zf:\n",
    "        zf.extractall(folder_path)\n",
    "else:\n",
    "    # Download the data and extract both zip files\n",
    "    boxlink = 'https://stsci.box.com/shared/static/8pjjn8nnaf1d1mev98ca9kc6mss7prmt.zip'\n",
    "    boxfile = 'stage2-selected.zip'\n",
    "    urllib.request.urlretrieve(boxlink, boxfile)\n",
    "    boxlink = 'https://stsci.box.com/shared/static/qstpome9vb95ay6aqlgvk0wvlku9ihay.zip'\n",
    "    boxfile = 'stage3-selected.zip'\n",
    "    urllib.request.urlretrieve(boxlink, boxfile)\n",
    "    # Extract both zip files\n",
    "    boxfile = './stage2-selected.zip'\n",
    "    with zipfile.ZipFile(boxfile) as zf:\n",
    "        zf.extractall(folder_path)        \n",
    "    boxfile = './stage3-selected.zip'\n",
    "    with zipfile.ZipFile(boxfile) as zf:\n",
    "        zf.extractall(folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "preceding-adoption",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "F560W-filter images:\n",
      "     1) ./data/det_image_seq1_MIRIMAGE_F560Wexp1_cal.fits\n",
      "     2) ./data/det_image_seq4_MIRIMAGE_F560Wexp1_cal.fits\n",
      "     3) ./data/det_image_seq3_MIRIMAGE_F560Wexp1_cal.fits\n",
      "     4) ./data/det_image_seq2_MIRIMAGE_F560Wexp1_cal.fits\n",
      "\n",
      "1 catalog found: ./data/complex_scene_F560W_combined_cat.ecsv\n",
      "\n",
      "F770W-filter images:\n",
      "     1) ./data/det_image_seq2_MIRIMAGE_F770Wexp1_cal.fits\n",
      "     2) ./data/det_image_seq3_MIRIMAGE_F770Wexp1_cal.fits\n",
      "     3) ./data/det_image_seq4_MIRIMAGE_F770Wexp1_cal.fits\n",
      "     4) ./data/det_image_seq1_MIRIMAGE_F770Wexp1_cal.fits\n",
      "\n",
      "1 catalog found: ./data/complex_scene_F770W_combined_cat.ecsv\n"
     ]
    }
   ],
   "source": [
    "filter_names = ['F560W', 'F770W']\n",
    "\n",
    "img_names = {}\n",
    "cat_names = {}\n",
    "for f in filter_names:\n",
    "    print('')\n",
    "    print(r'{0}-filter images:'.format(f))\n",
    "    names = glob.glob(folder_path + 'det_*' + f + '*_cal.fits')\n",
    "    for n in range(len(names)):\n",
    "        print(r'     {0}) {1}'.format(n+1, names[n]))\n",
    "    img_names[f] = names\n",
    "    names = glob.glob(folder_path + 'complex_*' + f + '*cat*.ecsv')\n",
    "    cat_names[f] = names\n",
    "    print('')\n",
    "    print(r'1 catalog found: {0}'.format(names[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dedicated-handy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./data/det_image_seq1_MIRIMAGE_F560Wexp1_cal.fits',\n",
       " './data/det_image_seq4_MIRIMAGE_F560Wexp1_cal.fits',\n",
       " './data/det_image_seq3_MIRIMAGE_F560Wexp1_cal.fits',\n",
       " './data/det_image_seq2_MIRIMAGE_F560Wexp1_cal.fits',\n",
       " './data/det_image_seq2_MIRIMAGE_F770Wexp1_cal.fits',\n",
       " './data/det_image_seq3_MIRIMAGE_F770Wexp1_cal.fits',\n",
       " './data/det_image_seq4_MIRIMAGE_F770Wexp1_cal.fits',\n",
       " './data/det_image_seq1_MIRIMAGE_F770Wexp1_cal.fits']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vals=list(img_names.values())\n",
    "images=vals[0]+vals[1]\n",
    "images"
   ]
  },
  {
   "cell_type": "raw",
   "id": "trained-bouquet",
   "metadata": {},
   "source": [
    "for image in images:\n",
    "\n",
    "    #print(image)\n",
    "    im = fits.open(image)\n",
    "    f = im[0].header['FILTER']\n",
    "    d = im[0].header['DETECTOR']\n",
    "    print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fitted-medicaid",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available Detectors: ['MIRIM']\n",
      "Available Filters: ['F560W', 'F770W']\n"
     ]
    }
   ],
   "source": [
    "dict_images = {'MIRIMAGE': {}}\n",
    "\n",
    "dict_filter = {}\n",
    "\n",
    "ff = []\n",
    "det = []\n",
    "detlist = []\n",
    "filtlist = []\n",
    "\n",
    "for image in images:\n",
    "\n",
    "    im = fits.open(image)\n",
    "    f = im[0].header['FILTER']\n",
    "    d = im[0].header['DETECTOR']\n",
    "    \n",
    "    if d == 'MIRIMAGE':\n",
    "        d = 'MIRIM'\n",
    "\n",
    "    ff.append(f)\n",
    "    det.append(d)\n",
    "\n",
    "    detlist = sorted(list(dict.fromkeys(det)))\n",
    "\n",
    "    unique_list_filters = []\n",
    "\n",
    "    for x in ff:\n",
    "\n",
    "        if x not in unique_list_filters:\n",
    "\n",
    "            dict_filter.setdefault(x, {})\n",
    "\n",
    "    for d_s in detlist:\n",
    "        dict_images[d_s] = dict_filter\n",
    "\n",
    "    filtlist = sorted(list(dict.fromkeys(dict_filter)))\n",
    "\n",
    "    if len(dict_images[d][f]) == 0:\n",
    "        dict_images[d][f] = {'images': [image]}\n",
    "    else:\n",
    "        dict_images[d][f]['images'].append(image)\n",
    "\n",
    "print(\"Available Detectors:\", detlist)\n",
    "print(\"Available Filters:\", filtlist)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "twelve-franchise",
   "metadata": {},
   "source": [
    "**Note**: in this particular example, we analyze each image separately to provide a general overview of the different steps necessary to perform PSF photometry and to highlight the different functions adopted in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "solar-village",
   "metadata": {},
   "outputs": [],
   "source": [
    "det = 'MIRIM'\n",
    "filt = 'F560W'\n",
    "\n",
    "im = fits.open(dict_images[det][filt]['images'][0])\n",
    "hdr560 = im[\"SCI\",1].header\n",
    "w560 = WCS(im[\"SCI\",1].header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "proud-vertex",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'F560W'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "small-pleasure",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./data/det_image_seq1_MIRIMAGE_F560Wexp1_cal.fits'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_images[det][filt]['images'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "plain-thriller",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MIRIMAGE': {},\n",
       " 'MIRIM': {'F560W': {'images': ['./data/det_image_seq1_MIRIMAGE_F560Wexp1_cal.fits',\n",
       "    './data/det_image_seq4_MIRIMAGE_F560Wexp1_cal.fits',\n",
       "    './data/det_image_seq3_MIRIMAGE_F560Wexp1_cal.fits',\n",
       "    './data/det_image_seq2_MIRIMAGE_F560Wexp1_cal.fits']},\n",
       "  'F770W': {'images': ['./data/det_image_seq2_MIRIMAGE_F770Wexp1_cal.fits',\n",
       "    './data/det_image_seq3_MIRIMAGE_F770Wexp1_cal.fits',\n",
       "    './data/det_image_seq4_MIRIMAGE_F770Wexp1_cal.fits',\n",
       "    './data/det_image_seq1_MIRIMAGE_F770Wexp1_cal.fits']}}}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "improving-avenue",
   "metadata": {},
   "source": [
    "### 3.1<font color='white'>-</font>Display the image<a class=\"anchor\" id=\"display_data\"></a> ###"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "consecutive-masters",
   "metadata": {},
   "source": [
    "To check that our image does not present artifacts and can be used in the analysis, we display it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "mighty-austria",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f90dc5ce6bc439592d5640bed970e4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Application(config='imviz', events=['call_viewer_method', 'close_snackbar_message', 'data_item_selected', 'des…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plt.figure(figsize=(12, 12))\n",
    "   \n",
    "data_sb = im[1].data\n",
    "#ax = plt.subplot(1, 1, 1)\n",
    "#plt.xlabel(\"X [px]\", fontdict=font2)\n",
    "#plt.ylabel(\"Y [px]\", fontdict=font2)\n",
    "#plt.title(filt, fontdict=font2)\n",
    "\n",
    "_, med, sig = sigma_clipped_stats(data_sb, sigma=5.0, maxiters=5)\n",
    "\n",
    "# Inputs: 2D array, min value, max value, title, x-axis label, y-axis label, colorbar label, colormap\n",
    "#imshow_me_wcolorbar(data_sb, med-1*sig, med+1*sig, 'Original image', 'x [MIRIM pixel]', 'y [MIRIM pixel]', 'MJy sr$^{-1}$', 'binary')\n",
    "\n",
    "imviz = Imviz()\n",
    "imviz.app\n",
    "\n",
    "#norm = simple_norm(data_sb, 'sqrt', percent=99.)\n",
    "#ax.imshow(data_sb, norm=norm, cmap='Greys')\n",
    "#plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "affiliated-suggestion",
   "metadata": {},
   "outputs": [],
   "source": [
    "imviz.load_data(data_sb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "hourly-voltage",
   "metadata": {},
   "outputs": [],
   "source": [
    "viewer = imviz.default_viewer\n",
    "viewer.cuts = '95%'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "metallic-analyst",
   "metadata": {},
   "source": [
    "### 3.2 Data Quality (DQ) Flags"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "greater-examination",
   "metadata": {},
   "source": [
    "Not all pixels should be used. We can use the Data Quality (DQ) flags to assess whether a pixel can be considered in calculations or not. [Here](https://jwst-pipeline.readthedocs.io/en/latest/jwst/references_general/references_general.html#data-quality-flags) you can find a description of the DQ flags.\n",
    "\n",
    "There is no one-size-fits-all solution for selecting pixels using the DQ flags. For this specific exercise, let's keep all pixels with DQ flag equal to:\n",
    "\n",
    "- 0 = Good pixel\n",
    "- 2 = Pixel saturated during integration\n",
    "- 4 = Jump detected during integration\n",
    "- 6 = Combination of DQ flags 2 and 4\n",
    "\n",
    "As we can see, the DQ flags can correspond to multiple features. We can use _dqflags.dqflags_to_mnemonics_ to convert the DQ integer values into more user-friendly names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "premier-quarter",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " DQ flag equal to 2: {'SATURATED'}\n",
      " DQ flag equal to 4: {'JUMP_DET'}\n",
      " DQ flag equal to 6: {'SATURATED', 'JUMP_DET'}\n"
     ]
    }
   ],
   "source": [
    "print(r' DQ flag equal to 2: {0}'.format(dqflags.dqflags_to_mnemonics(2, dqflags.group)))\n",
    "print(r' DQ flag equal to 4: {0}'.format(dqflags.dqflags_to_mnemonics(4, dqflags.group)))\n",
    "print(r' DQ flag equal to 6: {0}'.format(dqflags.dqflags_to_mnemonics(6, dqflags.group)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stone-affiliate",
   "metadata": {},
   "source": [
    "Let's flag all pixels with a DQ flag different from these four values:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "three-allergy",
   "metadata": {},
   "source": [
    "Third extension is the DQ flags\n",
    "https://jwst-pipeline.readthedocs.io/en/latest/jwst/data_products/science_products.html#rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "roman-cooling",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "311387 out of 1056768 pixels are not usable (~29.5%)\n"
     ]
    }
   ],
   "source": [
    "ok = np.zeros(im[1].data.shape, dtype='int')\n",
    "for v in [0, 2, 4, 6]:\n",
    "    ok = ok + np.where(im[3].data == v, 1, 0)\n",
    "\n",
    "im[1].data[ok == 0] = np.nan\n",
    "print(r'{0} out of {1} pixels are not usable (~{2:3.1f}%)'.format((ok == 0).sum(), im[1].data.shape[0]*im[1].data.shape[1], \n",
    "                                                                  (ok == 0).sum()/(im[1].data.shape[0]*im[1].data.shape[1])*100.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "republican-portsmouth",
   "metadata": {},
   "source": [
    "After masking, the same MIRI image looks different:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "hollywood-solomon",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b48e4f2c7d064dc284af0adf4622bfb0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Application(config='imviz', events=['call_viewer_method', 'close_snackbar_message', 'data_item_selected', 'des…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#imshow_me_wcolorbar(im[1].data, med-1*sig, med+1*sig, 'Image after masking', 'x [MIRIM pixel]', 'y [MIRIM pixel]', 'MJy sr$^{-1}$', 'binary')\n",
    "imviz = Imviz()\n",
    "imviz.app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "loving-buffer",
   "metadata": {},
   "outputs": [],
   "source": [
    "imviz.load_data(im[1].data)\n",
    "viewer = imviz.default_viewer\n",
    "viewer.cuts = '95%'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "premier-sound",
   "metadata": {},
   "source": [
    "As we can notice, the regions associated to the 4-quadrant phase mask (4QPM) coronagraphs disappeared from the image. The optical system of the 4QPM coronographs is different from that of the imager. Because of the way these optical elements affect the light transmission, the calibration of the 4QPM-coronograph regions is complicated and specific for these coronographs. Therefore, even though photons are detected in the regions of the coronagraphs during standard imaging observations, these regions should not be used while analyzing the Stage-2 image. If you run the _calwebb_image3_ pipeline (or the resample step in _calwebb_image2_), you will notice that the 4QPM regions are missing in the resampled image (_i2d.fits_) as well.\n",
    "\n",
    "Another feature we can notice is that two columns (# 385 and 386) were flagged. Although a qualitative assessment of the image (for example with ds9) does not show anything particularly different from the other columns, these two columns showed to be coupled and should not be used for science."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "suspected-prize",
   "metadata": {},
   "source": [
    "### 3.2<font color='white'>-</font>Convert image units and apply pixel area map<a class=\"anchor\" id=\"convert_data\"></a> ###"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "concrete-things",
   "metadata": {},
   "source": [
    "The unit of the Level-2 and Level-3 Images from the pipeline is MJy/sr (hence a surface brightness). The actual unit of the image can be checked from the header keyword **BUNIT**. The scalar conversion constant is copied to the header keyword **PHOTMJSR**, which gives the conversion from DN/s to megaJy/steradian. For our analysis we revert back to DN/s.\n",
    "\n",
    "For images that have not been transformed into a distortion-free frame (i.e. not drizzled), a correction must be applied to account for the different on-sky pixel size across the field of view. A pixel area map (PAM), which is an image where each pixel value describes that pixel's area on the sky relative to the native plate scale, is used for this correction. In the stage 2 of the JWST pipeline, the PAM is copied into an image extension called **AREA** in the science data product. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "interim-popularity",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conversion factor from MJy/sr to DN/s for filter F560W: 1.127009987831116\n"
     ]
    }
   ],
   "source": [
    "imh = im[1].header\n",
    "data = data_sb / imh['PHOTMJSR']\n",
    "print('Conversion factor from {units} to DN/s for filter {f}:'.format(units=imh['BUNIT'], f=filt), imh['PHOTMJSR'])\n",
    "area = im[4].data\n",
    "data = data * area"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "further-supervision",
   "metadata": {},
   "source": [
    "4.<font color='white'>-</font>Create synthetic PSF (with WebbPSF) <a class=\"anchor\" id=\"webbpsf_intro\"></a>\n",
    "------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "protective-hierarchy",
   "metadata": {},
   "source": [
    "WebbPSF is a Python package that computes simulated PSFs for NASA’s JWST and Nancy Grace Roman Space Telescope (formerly WFIRST). WebbPSF transforms models of telescope and instrument optical state into PSFs, taking into account detector pixel scales, rotations, filter profiles, and point source spectra. It is not a full optical model of JWST, but rather a tool for transforming optical path difference (OPD) maps, created with some other tool, into the resulting PSFs as observed with JWST’s or Roman’s instruments. For a full documentation on WebbPSF, see [here](https://webbpsf.readthedocs.io/en/latest/) and for is capability and limitation, see [here](https://webbpsf.readthedocs.io/en/latest/intro.html).\n",
    "\n",
    "The function below allows to create a single PSF or a grid of PSFs (the PSF can also be saved as a fits file). First, we need to specify the instrument (MIRI), detector, and filter. Then, to create a single (or grid) PSF we use the webbPSF method *psf_grid*, which will output a (list of or single) photutils GriddedPSFModel object(s). A tutorial notebook on the *psf_grid* method can be found [here](https://github.com/spacetelescope/webbpsf/blob/stable/notebooks/Gridded_PSF_Library.ipynb).\n",
    "\n",
    "**Important Parameters**:\n",
    "\n",
    "* `num`: the total number of fiducial PSFs to be created and saved in the files. This\n",
    "    number must be a square number (4, 9, 16, etc.)\n",
    "\n",
    "* `oversample`: the oversample factor we want to adopt in the PSF creation.\n",
    "\n",
    "* `fov`: the size in pixel of the PSF model. The size depends on the shape of the PSF and how much flux is contained in the wings of the PSFs (i.e., a small field of view will exclude more flux from the PSF wings). However, increasing the field of view, increase also the computational time, so we need to find a reasonable compromise.\n",
    "\n",
    "* `source`: the source spectrum we want to adopt. Source spectra are defined using the function  `webbpsf.specFromSpectralType` where we need to define the spectral type and the model library (e.g., webbpsf.specFromSepectralType('G5V', catalog='phoenix')). See also note below on the default spectrum depending on if pysynphot is installed or not. \n",
    "\n",
    "* `all_detectors`: run all detectors for the instrument. Since we analyze only 1 detector, we set `all_detectors = False` (we do not need to create a PSF model for all MIRI detectors).\n",
    "\n",
    "* `use_detsampled_psf`: If the grid of PSFs returned will be detector sampled (made by binning down the oversampled PSF) or oversampled by the factor defined by the oversample. For our analysis, we want to create an oversampled PSF model, so we set `use_detsampled_psf = False`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "urban-ability",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    \n",
    "**Note on centering**: by default, the PSF will be centered at the exact center of the output array. This means that if the PSF is computed on an array with an odd number of pixels, the PSF will be centered exactly on the central pixel. If the PSF is computed on an array with even size, it will be centered on the “crosshairs” at the intersection of the central four pixels.\n",
    "\n",
    "**Note on normalization**: by default, PSFs are normalized to total intensity = 1.0 at the entrance pupil (i.e. at the JWST OTE primary). A PSF calculated for an infinite aperture would thus have integrated intensity =1.0. A PSF calculated on any smaller finite subarray will have some finite encircled energy less than one.\n",
    "\n",
    "**Note on source spectrum**: The default source spectrum is, if *pysynphot* is installed, a G2V star spectrum from Castelli & Kurucz (2004). Without *pysynphot*, the default is a simple flat spectrum such that the same number of photons are detected at each wavelength.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "dressed-underwear",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_psf_model(det='MIRIM', filt='F770W', fov=101, source=None, create_grid=False, num=9, save_psf=False, \n",
    "                     detsampled=False):\n",
    "\n",
    "    miri = webbpsf.MIRI()\n",
    "\n",
    "    miri.detector = det \n",
    "    miri.filter = filt\n",
    "\n",
    "    print(\"Using a {field}\".format(field=fov), \"px fov\")\n",
    "\n",
    "    if create_grid:\n",
    "        print(\"\")\n",
    "        print(\"Creating a grid of PSF for filter {filt} and detector {det}\".format(filt=filt, det=det))\n",
    "        print(\"\")\n",
    "        num = num\n",
    "        \n",
    "        if save_psf:\n",
    "            \n",
    "            outname = 'PSF_%s_samp4_fov%d_npsfs%d.fits' % (filt, fov, num)\n",
    "            psf = miri.psf_grid(num_psfs=num, oversample=4, source=source, all_detectors=False, fov_pixels=fov, \n",
    "                               save=True, outfile=os.path.join(psfs_dir,outname), use_detsampled_psf=detsampled)\n",
    "\n",
    "        else:\n",
    "        \n",
    "            psf = miri.psf_grid(num_psfs=num, oversample=4, source=source, all_detectors=False, fov_pixels=fov, \n",
    "                               use_detsampled_psf=detsampled)\n",
    "            \n",
    "    else:\n",
    "        print(\"\")\n",
    "        print(\"Creating a single PSF for filter {filt} and detector {det}\".format(filt=filt, det=det))\n",
    "        print(\"\")\n",
    "        num = 1\n",
    "        \n",
    "        if save_psf:\n",
    "\n",
    "            outname = 'PSF_%s_samp4_fov%d_npsfs%d.fits' % (filt, fov, num)\n",
    "            psf = miri.psf_grid(num_psfs=num, oversample=4, source=source, all_detectors=False, fov_pixels=fov, \n",
    "                               save=True, outfile=os.path.join(psfs_dir,outname), use_detsampled_psf=detsampled)\n",
    "        \n",
    "        else:\n",
    "      \n",
    "            psf = miri.psf_grid(num_psfs=num, oversample=4, source=source, all_detectors=False, fov_pixels=fov, \n",
    "                               use_detsampled_psf=detsampled)\n",
    "        \n",
    "    return psf     "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "infrared-clark",
   "metadata": {},
   "source": [
    "### 4.1<font color='white'>-</font>Create the single PSF<a class=\"anchor\" id=\"single_webbpsf\"></a> ###"
   ]
  },
  {
   "cell_type": "raw",
   "id": "funky-champion",
   "metadata": {},
   "source": [
    "psfs_dir = 'PSF_MODELS/'\n",
    "\n",
    "if not os.path.exists(psfs_dir):\n",
    "    os.makedirs(psfs_dir)\n",
    "\n",
    "psf_webbpsf_single = create_psf_model(det=det, filt=filt, fov=11, source=None, create_grid=False, save_psf=True, \n",
    "                                      detsampled=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "elder-score",
   "metadata": {},
   "source": [
    "Although the above commands will create a PSF model using WebbPSF, the MIRI team has premade PSFs available for direct download so you don't need to install and run WebbPSF on your own."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hispanic-blackberry",
   "metadata": {},
   "outputs": [],
   "source": [
    "from webbpsf.utils import to_griddedpsfmodel\n",
    "\n",
    "psf_webbpsf_single = to_griddedpsfmodel('./PSF_MODELS/PSF_F560W_samp4_fov11_npsfs1_mirim.fits')  # file created 2 cells above\n",
    "psf_webbpsf_single"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "otherwise-place",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(\"PSF_MODELS/\"):\n",
    "    print(\"PSF_MODELS Exist, But worth DOUBLE-CHECKING all latest PSF files are there\")\n",
    "else:\n",
    "    url = 'https://data.science.stsci.edu/redirect/JWST/jwst-data_analysis_tools/MIRI_photometry/PSF_MODELS.tar.gz'\n",
    "    urllib.request.urlretrieve(url, './PSF_MODELS.tar.gz')\n",
    "    \n",
    "    # Unzip Tar Files\n",
    "    import tarfile\n",
    "\n",
    "    tar = tarfile.open('./PSF_MODELS.tar.gz', \"r:gz\")\n",
    "    tar.extractall()\n",
    "    tar.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "opening-monday",
   "metadata": {},
   "source": [
    "### 4.2<font color='white'>-</font>Display the single PSF<a class=\"anchor\" id=\"display_single_webbpsf\"></a> ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "leading-landscape",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 12))\n",
    "\n",
    "ax = plt.subplot(1, 1, 1)\n",
    "\n",
    "norm_psf = simple_norm(psf_webbpsf_single.data[0], 'log', percent=99.)\n",
    "ax.set_title(filt, fontsize=40)\n",
    "ax.imshow(psf_webbpsf_single.data[0], norm=norm_psf)\n",
    "ax.set_xlabel('X [px]', fontsize=30)\n",
    "ax.set_ylabel('Y [px]', fontsize=30)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "minor-craps",
   "metadata": {},
   "source": [
    "### 4.3<font color='white'>-</font>Create the grid of PSFs<a class=\"anchor\" id=\"grid_webbpsf\"></a> ###"
   ]
  },
  {
   "cell_type": "raw",
   "id": "spare-appeal",
   "metadata": {},
   "source": [
    "psf_webbpsf_grid = create_psf_model(det=det, filt=filt, fov=11, source=None, create_grid=True, num=16, \n",
    "                                    save_psf=True, detsampled=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "independent-webcam",
   "metadata": {},
   "source": [
    "Although the above commands will create a PSF model using WebbPSF, the MIRI team has premade PSFs available for direct download so you don't need to install and run WebbPSF on your own."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "irish-reach",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(\"PSF_MODELS/\"):\n",
    "    print(\"PSF_MODELS Exist, But worth DOUBLE-CHECKING all latest PSF files are there\")\n",
    "else:\n",
    "    url = 'https://data.science.stsci.edu/redirect/JWST/jwst-data_analysis_tools/MIRI_photometry/PSF_MODELS.tar.gz'\n",
    "    urllib.request.urlretrieve(url, './PSF_MODELS.tar.gz')\n",
    "    \n",
    "    # Unzip Tar Files\n",
    "    import tarfile\n",
    "\n",
    "    tar = tarfile.open('./PSF_MODELS.tar.gz', \"r:gz\")\n",
    "    tar.extractall()\n",
    "    tar.close()\n",
    "\n",
    "    from webbpsf.utils import to_griddedpsfmodel\n",
    "\n",
    "psf_webbpsf_grid = to_griddedpsfmodel('./PSF_MODELS/PSF_F560W_samp4_fov11_npsfs16_mirim.fits')  # file created 2 cells above\n",
    "psf_webbpsf_grid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "separated-courage",
   "metadata": {},
   "source": [
    "### 4.4<font color='white'>-</font>Display the grid of PSFs<a class=\"anchor\" id=\"display_grid_webbpsf\"></a> ###"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "neural-president",
   "metadata": {},
   "source": [
    "We show the grid of PSFs with their positions in detector coordinates and the difference from the mean to highlight the differences between the different models. We use the webbPSF function *gridded_library.display_psf_grid*."
   ]
  },
  {
   "cell_type": "raw",
   "id": "earned-resolution",
   "metadata": {},
   "source": [
    "#Help Desk Ticket in, this isn't working at the moment\n",
    "webbpsf.gridded_library.display_psf_grid(psf_webbpsf_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "happy-harbor",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "ax = plt.subplot(1, 1, 1)\n",
    "plt.title('Difference central PSF - corner PSF')        \n",
    "model1 = psf_webbpsf_single.data[0]\n",
    "model2 = psf_webbpsf_grid.data[0]\n",
    "\n",
    "ratio = (model1 - model2)\n",
    "aa = np.max(np.abs(ratio))\n",
    "divider = make_axes_locatable(ax)\n",
    "im = ax.imshow(ratio, origin='lower', vmin=-aa, vmax=aa, cmap='RdBu')\n",
    "cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "plt.colorbar(im, cax=cax)\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "distinct-longitude",
   "metadata": {},
   "source": [
    "5.<font color='white'>-</font>Create PSF model building an effective PSF<a class=\"anchor\" id=\"epsf_intro\"></a>\n",
    "------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "classical-weight",
   "metadata": {},
   "source": [
    "More information on the PhotUtils Effective PSF can be found [here](https://photutils.readthedocs.io/en/stable/epsf.html).\n",
    "\n",
    "The process of creating an effective PSF can be summarized as follows:\n",
    "\n",
    "* Find the stars in the image.\n",
    "* Select the stars we want to use for building the effective PSF. \n",
    "* Build the effective PSF."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "closed-jungle",
   "metadata": {},
   "source": [
    "### 5.1<font color='white'>-</font>Calculate the background<a class=\"anchor\" id=\"bkg\"></a> ###"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "played-lotus",
   "metadata": {},
   "source": [
    "Defined above"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ordered-anger",
   "metadata": {},
   "source": [
    "### 5.2<font color='white'>-</font>Find sources in the image<a class=\"anchor\" id=\"find\"></a> ###"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accepting-kinase",
   "metadata": {},
   "source": [
    "To find sources in the image, we use the [DAOStarFinder](https://photutils.readthedocs.io/en/stable/api/photutils.detection.DAOStarFinder.html) function. \n",
    "\n",
    "[DAOStarFinder](https://photutils.readthedocs.io/en/stable/api/photutils.detection.DAOStarFinder.html) detects stars in an image using the DAOFIND ([Stetson 1987](https://ui.adsabs.harvard.edu/abs/1987PASP...99..191S/abstract)) algorithm. DAOFIND searches images for local density maxima that have a peak amplitude greater than `threshold` (approximately; threshold is applied to a convolved image) and have a size and shape similar to the defined 2D Gaussian kernel.\n",
    "\n",
    "**Important parameters**:\n",
    "\n",
    "* `threshold`: The absolute image value above which to select sources.\n",
    "* `fwhm`: The full-width half-maximum (FWHM) of the major axis of the Gaussian kernel in units of pixels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incredible-rings",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_stars(det='MIRIM', filt='F770W', threshold=3, var_bkg=False):\n",
    "    \n",
    "    print('Finding stars --- Detector: {d}, Filter: {f}'.format(f=filt, d=det))\n",
    "\n",
    "    sigma_psf = dict_utils[filt]['psf fwhm']\n",
    "\n",
    "    print('FWHM for the filter {f}:'.format(f=filt), sigma_psf, \"px\")\n",
    "    \n",
    "    data_bkgsub, std = calc_bkg(var_bkg=True)\n",
    "    \n",
    "    daofind = DAOStarFinder(threshold=threshold * std, fwhm=sigma_psf, exclude_border=True)\n",
    "    found_stars = daofind(data_bkgsub)\n",
    "    \n",
    "    print('')\n",
    "    print('Number of sources found in the image:', len(found_stars))\n",
    "    print('-------------------------------------')\n",
    "    print('')\n",
    "    \n",
    "    return data_bkgsub, found_stars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chronic-celebration",
   "metadata": {},
   "outputs": [],
   "source": [
    "det = 'MIRIM'\n",
    "filt = 'F560W'\n",
    "\n",
    "im = fits.open(dict_images[det][filt]['images'][0])\n",
    "hdr560 = im[\"SCI\",1].header\n",
    "w560 = WCS(im[\"SCI\",1].header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hearing-sherman",
   "metadata": {},
   "outputs": [],
   "source": [
    "tic = time.perf_counter()\n",
    "\n",
    "data_bkgsub, found_stars = find_stars(det=det, filt=filt, threshold=5, var_bkg=True)\n",
    "\n",
    "toc = time.perf_counter()\n",
    "\n",
    "print(\"Elapsed Time for finding stars:\", toc - tic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "central-bubble",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print 10 lines of the table\n",
    "found_stars.pprint_all(max_lines=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "about-cutting",
   "metadata": {},
   "source": [
    "The column description is almost straightforward. The three parameters that need further description are:\n",
    "- sharpness : (height of the central pixel - mean of the surrounding non-bad pixels) / (height of the best fitting Gaussian function at that point);\n",
    "- roundness1 : source symmetry;\n",
    "- roundness2 : (difference in the height of the best fitting Gaussian function in x - the height of the the best fitting Gaussian function in y) / (average of the best fitting Gaussian functions in x and y).\n",
    "\n",
    "These parameters can be used to discern between stars, galaxies or spurious detections. It is possible to setup _DAOStarFinder_ to exclude a priori objects outside a specific range of sharpness/roundness1/roundness2. Finally, note that the magnitude is defined as $-2.5\\log_{10}(\\text{peak density/detection threshold})$, which is just a rough estimate of the magnitude. An exaustive description of inputs and outputs is also provided [here](https://iraf.net/irafhelp.php?val=daofind).\n",
    "\n",
    "Let's plot what we have found. We can use _imshow_me_wcolorbar_setup_, which is a function similar to _imshow_me_wcolorbar_ we used before but it allows us to keep plotting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lined-dryer",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "imshow_me_wcolorbar_setup(data_bkgsub, -0.1, 0.25, 'Image', 'x [MIRIM pixel]', 'y [MIRIM pixel]', 'MJy sr$^{-1}$', 'binary')\n",
    "ax.scatter(found_stars['xcentroid'], found_stars['ycentroid'], lw=0.5, s=15, marker='o', edgecolors='red', facecolors='none')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dress-league",
   "metadata": {},
   "source": [
    "### 5.3<font color='white'>-</font>Select sources<a class=\"anchor\" id=\"select\"></a> ###"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "likely-string",
   "metadata": {},
   "source": [
    "At the beginning, we used the DQ flags to mask some pixels and kept only those with DQ$=$0, 2, 4, 6. Although still perfectly usable, you might want to keep track of pixels that saturated during an integration or were hit by a cosmic ray. For this reason, we define a flag by checking all pixels within each aperture radius we used:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "effective-acting",
   "metadata": {},
   "outputs": [],
   "source": [
    "found_stars['flags'] = np.zeros(len(found_stars), dtype=int)\n",
    "\n",
    "rad = 5.\n",
    "\n",
    "for s in found_stars:\n",
    "        jmin = max(1, int(np.floor(s['ycentroid']-rad)))\n",
    "        jmax = min(round(s['ycentroid']+rad)+1, im[1].shape[0])\n",
    "        imin = max(1, int(np.floor(s['xcentroid']-rad)))\n",
    "        imax = min(round(s['xcentroid']+rad)+1, im[1].shape[1])\n",
    "        if (np.sum(im[3].data[jmin:jmax, imin:imax] == 6) > 0):\n",
    "            s['flags'] = 6\n",
    "        elif (np.sum(im[3].data[jmin:jmax, imin:imax] == 2) > 0):\n",
    "            s['flags'] = 2\n",
    "        elif (np.sum(im[3].data[jmin:jmax, imin:imax] == 4) > 0):\n",
    "            s['flags'] = 4\n",
    "            \n",
    "print('                            Sources found: {0}'.format(len(found_stars)))\n",
    "print('Sources with \"SATURATED\" pixels within rad=5: {0}'.format(np.sum(np.logical_or(found_stars['flags'] == 2, found_stars['flags'] == 6))))\n",
    "print(' Sources with \"JUMP_DET\" pixels within rad=5: {0}'.format(np.sum(np.logical_or(found_stars['flags'] == 4, found_stars['flags'] == 6))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "finished-seeking",
   "metadata": {},
   "source": [
    "Let's check if our flag works. For example, let's test the jump-detection flag:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "blind-helmet",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flag for stars with \"jump\" pixel within rad=5 aperture\n",
    "jump = np.logical_or(found_stars['flags'] == 4, found_stars['flags'] == 6)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "imshow_me_wcolorbar_setup(data_bkgsub, -0.1, 0.25, 'Stars with \"jump\" pixel within r2 aperture', 'x [MIRIM pixel]', 'y [MIRIM pixel]', 'MJy sr$^{-1}$', 'binary')\n",
    "ax.scatter(found_stars['xcentroid'], found_stars['ycentroid'], lw=0.5, s=15, marker='o', edgecolors='red', facecolors='none')\n",
    "ax.scatter(found_stars['xcentroid'][jump], found_stars['ycentroid'][jump], c='deepskyblue', lw=0, s=20)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "different-butter",
   "metadata": {},
   "source": [
    "We can adopt different methods to select sources we want to use to build an effective PSF. Here, we select objects applying a brightness cut (we do not want to include objects that are too faint) and using the `roundness2` and `sharpness` parameters provided in the [DAOStarFinder](https://photutils.readthedocs.io/en/stable/api/photutils.detection.DAOStarFinder.html) output catalog.\n",
    "\n",
    "`roundness2` measures the ratio of the difference in the height of the best fitting Gaussian function in x minus the best fitting Gaussian function in y, divided by the average of the best fitting Gaussian functions in x and y.\n",
    "\n",
    "`sharpness` measures the ratio of the difference between the height of the central pixel and the mean of the surrounding non-bad pixels in the convolved image, to the height of the best fitting Gaussian function at that point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "described-boring",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 8))\n",
    "plt.clf()\n",
    "\n",
    "ax1 = plt.subplot(2, 1, 1)\n",
    "\n",
    "ax1.set_xlabel('mag', fontdict=font2)\n",
    "ax1.set_ylabel('sharpness', fontdict=font2)\n",
    "\n",
    "xlim0 = np.min(found_stars['mag']) - 0.25\n",
    "xlim1 = np.max(found_stars['mag']) + 0.25\n",
    "ylim0 = np.min(found_stars['sharpness']) - 0.15\n",
    "ylim1 = np.max(found_stars['sharpness']) + 0.15\n",
    "\n",
    "ax1.set_xlim(xlim0, xlim1)\n",
    "ax1.set_ylim(ylim0, ylim1)\n",
    "\n",
    "ax1.xaxis.set_major_locator(ticker.AutoLocator())\n",
    "ax1.xaxis.set_minor_locator(ticker.AutoMinorLocator())\n",
    "ax1.yaxis.set_major_locator(ticker.AutoLocator())\n",
    "ax1.yaxis.set_minor_locator(ticker.AutoMinorLocator())\n",
    "\n",
    "ax1.scatter(found_stars['mag'], found_stars['sharpness'], s=10, color='k')\n",
    "\n",
    "sh_inf = 0.68\n",
    "sh_sup = 0.82\n",
    "mag_lim = -4.0\n",
    "\n",
    "ax1.plot([xlim0, xlim1], [sh_sup, sh_sup], color='r', lw=3, ls='--')\n",
    "ax1.plot([xlim0, xlim1], [sh_inf, sh_inf], color='r', lw=3, ls='--')\n",
    "ax1.plot([mag_lim, mag_lim], [ylim0, ylim1], color='r', lw=3, ls='--')\n",
    "\n",
    "ax2 = plt.subplot(2, 1, 2)\n",
    "\n",
    "ax2.set_xlabel('mag', fontdict=font2)\n",
    "ax2.set_ylabel('roundness', fontdict=font2)\n",
    "\n",
    "ylim0 = np.min(found_stars['roundness2']) - 0.25\n",
    "ylim1 = np.max(found_stars['roundness2']) - 0.25\n",
    "\n",
    "ax2.set_xlim(xlim0, xlim1)\n",
    "ax2.set_ylim(ylim0, ylim1)\n",
    "\n",
    "ax2.xaxis.set_major_locator(ticker.AutoLocator())\n",
    "ax2.xaxis.set_minor_locator(ticker.AutoMinorLocator())\n",
    "ax2.yaxis.set_major_locator(ticker.AutoLocator())\n",
    "ax2.yaxis.set_minor_locator(ticker.AutoMinorLocator())\n",
    "\n",
    "round_inf = -0.40\n",
    "round_sup = 0.40\n",
    "\n",
    "ax2.scatter(found_stars['mag'], found_stars['roundness2'], s=10, color='k')\n",
    "\n",
    "ax2.plot([xlim0, xlim1], [round_sup, round_sup], color='r', lw=3, ls='--')\n",
    "ax2.plot([xlim0, xlim1], [round_inf, round_inf], color='r', lw=3, ls='--')\n",
    "ax2.plot([mag_lim, mag_lim], [ylim0, ylim1], color='r', lw=3, ls='--')\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "running-impression",
   "metadata": {},
   "source": [
    "### 5.4<font color='white'>-</font>Create catalog of selected sources<a class=\"anchor\" id=\"create_cat\"></a> ###"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spoken-forty",
   "metadata": {},
   "source": [
    "We can also include a separation criteria if we want to retain in the final catalog only the stars that are well isolated. In particular, we can select only the stars that do not have a neighbour closer than X pixel, where X is a parameter that can be set manually.\n",
    "\n",
    "**Note**: The magnitude limit and the minimum distance to the closest neighbour depend on the user science case (i.e.; number of stars in the field of view, crowding, number of bright sources, minimum number of stars required to build the ePSF, etc.) and must be modified accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "canadian-logic",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = ((found_stars['mag'] < mag_lim) & (found_stars['roundness2'] > round_inf)\n",
    "        & (found_stars['roundness2'] < round_sup) & (found_stars['sharpness'] > sh_inf) \n",
    "        & (found_stars['sharpness'] < sh_sup))\n",
    "\n",
    "found_stars_sel = found_stars[mask]\n",
    "found_stars_sel_f560w = found_stars_sel\n",
    "\n",
    "print('Number of stars selected to build ePSF:', len(found_stars_sel))\n",
    "\n",
    "# if we include the separation criteria:\n",
    "\n",
    "d = []\n",
    "\n",
    "# we do not want any stars in a 10 px radius. \n",
    "\n",
    "min_sep = 10\n",
    "\n",
    "x_tot = found_stars['xcentroid']\n",
    "y_tot = found_stars['ycentroid']\n",
    "\n",
    "for xx, yy in zip(found_stars_sel['xcentroid'], found_stars_sel['ycentroid']):\n",
    "\n",
    "    sep = []\n",
    "    dist = np.sqrt((x_tot - xx)**2 + (y_tot - yy)**2)\n",
    "    sep = np.sort(dist)[1:2][0]\n",
    "    d.append(sep)\n",
    "\n",
    "found_stars_sel['min distance'] = d\n",
    "mask_dist = (found_stars_sel['min distance'] > min_sep)\n",
    "\n",
    "found_stars_sel2 = found_stars_sel[mask_dist]\n",
    "found_stars_sel2_fw = found_stars_sel2\n",
    "\n",
    "print('Number of stars selected to build ePSF \\\n",
    "including \"mimimum distance closest neighbour\" selection):', len(found_stars_sel2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cellular-thriller",
   "metadata": {},
   "source": [
    "### 5.5<font color='white'>-</font>Build the effective PSF<a class=\"anchor\" id=\"build_epsf\"></a> ###"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "invalid-horizon",
   "metadata": {},
   "source": [
    "We Build the effective PSF using [EPSBuilder](https://photutils.readthedocs.io/en/stable/api/photutils.psf.EPSFBuilder.html#photutils.psf.EPSFBuilder) function.\n",
    "\n",
    "First, we exclude the objects for which the bounding box exceed the detector edge. Then, we extract cutouts of the stars using the [extract_stars()](https://photutils.readthedocs.io/en/stable/api/photutils.psf.extract_stars.html#photutils.psf.extract_stars) function. The size of the cutout is determined by the parameter `size` in our function *build_epsf*. Once we have the object containing the cutouts of our selected stars, we can build our ePSF using [EPSFBuilder](https://photutils.readthedocs.io/en/stable/api/photutils.psf.EPSFBuilder.html#photutils.psf.EPSFBuilder) class. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "geographic-ireland",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "Here we limit the maximum number of iterations to 3 (to limit its run time), but in practice one should use about 10 or more iterations.\n",
    "    \n",
    "<div >"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "continuing-campus",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_epsf(det='MIRIM', filt='F770W', size=11, found_table=None, oversample=4, iters=10):\n",
    "    \n",
    "    hsize = (size - 1) / 2\n",
    "    \n",
    "    x = found_table['xcentroid']\n",
    "    y = found_table['ycentroid']\n",
    "    \n",
    "    mask = ((x > hsize) & (x < (data.shape[1] - 1 - hsize)) & (y > hsize) & (y < (data.shape[0] - 1 - hsize)))\n",
    "\n",
    "    stars_tbl = Table()\n",
    "    stars_tbl['x'] = x[mask]\n",
    "    stars_tbl['y'] = y[mask]\n",
    "    \n",
    "    data_bkgsub, _ = calc_bkg()\n",
    "    \n",
    "    nddata = NDData(data=data_bkgsub)\n",
    "    stars = extract_stars(nddata, stars_tbl, size=size)\n",
    "\n",
    "    print('Creating ePSF --- Detector {d}, filter {f}'.format(f=filt, d=det))\n",
    "\n",
    "    epsf_builder = EPSFBuilder(oversampling=oversample, maxiters=iters, progress_bar=True)\n",
    "\n",
    "    epsf, fitted_stars = epsf_builder(stars)\n",
    "    \n",
    "    return epsf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adaptive-injury",
   "metadata": {},
   "outputs": [],
   "source": [
    "epsf = build_epsf(det=det, filt=filt, size=11, found_table=found_stars_sel, oversample=4, iters=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "personal-institution",
   "metadata": {},
   "source": [
    "### 5.6<font color='white'>-</font>Display the effective PSF<a class=\"anchor\" id=\"display_epsf\"></a> ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "excess-multimedia",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 12))\n",
    "\n",
    "ax = plt.subplot(1, 1, 1)\n",
    "\n",
    "norm_epsf = simple_norm(epsf.data, 'log', percent=99.)\n",
    "plt.title(filt, fontsize=30)\n",
    "ax.imshow(epsf.data, norm=norm_epsf)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "august-planning",
   "metadata": {},
   "source": [
    "6.<font color='white'>-</font>Perform PSF Photometry<a class=\"anchor\" id=\"psf_phot\"></a>\n",
    "------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spare-boards",
   "metadata": {},
   "source": [
    "For general information on PSF Photometry with PhotUtils see [here](https://photutils.readthedocs.io/en/stable/psf.html). \n",
    "\n",
    "Photutils provides three classes to perform PSF Photometry: [BasicPSFPhotometry](https://photutils.readthedocs.io/en/stable/api/photutils.psf.BasicPSFPhotometry.html#photutils.psf.BasicPSFPhotometry), [IterativelySubtractedPSFPhotometry](https://photutils.readthedocs.io/en/stable/api/photutils.psf.IterativelySubtractedPSFPhotometry.html#photutils.psf.IterativelySubtractedPSFPhotometry), and [DAOPhotPSFPhotometry](https://photutils.readthedocs.io/en/stable/api/photutils.psf.DAOPhotPSFPhotometry.html#photutils.psf.DAOPhotPSFPhotometry). Together these provide the core workflow to make photometric measurements given an appropriate PSF (or other) model.\n",
    "\n",
    "[BasicPSFPhotometry](https://photutils.readthedocs.io/en/stable/api/photutils.psf.BasicPSFPhotometry.html#photutils.psf.BasicPSFPhotometry) implements the minimum tools for model-fitting photometry. At its core, this involves finding sources in an image, grouping overlapping sources into a single model, fitting the model to the sources, and subtracting the models from the image. In DAOPHOT parlance, this is essentially running the “FIND, GROUP, NSTAR, SUBTRACT” once.\n",
    "\n",
    "[IterativelySubtractedPSFPhotometry](https://photutils.readthedocs.io/en/stable/api/photutils.psf.IterativelySubtractedPSFPhotometry.html#photutils.psf.IterativelySubtractedPSFPhotometry) (adopted here) is similar to [BasicPSFPhotometry](https://photutils.readthedocs.io/en/stable/api/photutils.psf.BasicPSFPhotometry.html#photutils.psf.BasicPSFPhotometry), but it adds a parameter called `n_iters` which is the number of iterations for which the loop “FIND, GROUP, NSTAR, SUBTRACT, FIND…” will be performed. This class enables photometry in a scenario where there exists significant overlap between stars that are of quite different brightness. For instance, the detection algorithm may not be able to detect a faint and bright star very close together in the first iteration, but they will be detected in the next iteration after the brighter stars have been fit and subtracted. Like [BasicPSFPhotometry](https://photutils.readthedocs.io/en/stable/api/photutils.psf.BasicPSFPhotometry.html#photutils.psf.BasicPSFPhotometry), it does not include implementations of the stages of this process, but it provides the structure in which those stages run.\n",
    "\n",
    "**Important parameters**:\n",
    "\n",
    "* `finder`: classes to find stars in the image. We use [DAOStarFinder](https://photutils.readthedocs.io/en/stable/api/photutils.detection.DAOStarFinder.html).\n",
    "\n",
    "* `group_maker`:  clustering algorithm in order to label the sources according to groups. We use [DAOGroup](https://photutils.readthedocs.io/en/stable/api/photutils.psf.DAOGroup.html#photutils.psf.DAOGroup). The method group_stars divides an entire starlist into sets of distinct, self-contained groups of mutually overlapping stars. It accepts as input a list of stars and determines which stars are close enough to be capable of adversely influencing each others’ profile fits. [DAOGroup](https://photutils.readthedocs.io/en/stable/api/photutils.psf.DAOGroup.html#photutils.psf.DAOGroup) aceepts one parameter, `crit_separation`, which is the distance, in units of pixels, such that any two stars separated by less than this distance will be placed in the same group.\n",
    "\n",
    "* `fitter`: algorithm to fit the sources simultaneously for each group. We use an astropy fitter, [LevMarLSQFitter](https://docs.astropy.org/en/stable/api/astropy.modeling.fitting.LevMarLSQFitter.html#astropy.modeling.fitting.LevMarLSQFitter). \n",
    "\n",
    "* `niters`: number of iterations for which the \"psf photometry\" loop described above is performed.\n",
    "\n",
    "* `fitshape`: Rectangular shape around the center of a star which will be used to collect the data to do the fitting. \n",
    "\n",
    "* `aperture_radius`: The radius (in units of pixels) used to compute initial estimates for the fluxes of sources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eastern-stroke",
   "metadata": {},
   "outputs": [],
   "source": [
    "def psf_phot(data=None, det='MIRIM', filt='F560W', th=2000, psf=None, ap_radius=3.5, save_residuals=False, \n",
    "             save_output=False):\n",
    "\n",
    "    fitter = LevMarLSQFitter()\n",
    "    mmm_bkg = MMMBackground()\n",
    "        \n",
    "    sigma_psf = dict_utils[filt]['psf fwhm']\n",
    "    print('FWHM for filter {f}:'.format(f=filt), sigma_psf*2)\n",
    "    \n",
    "    _, std = calc_bkg()\n",
    "    \n",
    "    daofind = DAOStarFinder(threshold=th * std, fwhm=sigma_psf)\n",
    "    \n",
    "    daogroup = DAOGroup(5.0 * sigma_psf)\n",
    "    \n",
    "    psf_model = psf.copy()\n",
    "    \n",
    "    print('Performing the PSF photometry --- Detector {d}, filter {f}'.format(f=filt, d=det))\n",
    "            \n",
    "    tic = time.perf_counter()\n",
    "    \n",
    "    phot = IterativelySubtractedPSFPhotometry(finder=daofind, group_maker=daogroup,\n",
    "                                              bkg_estimator=mmm_bkg, psf_model=psf_model,\n",
    "                                              fitter=fitter,\n",
    "                                              niters=3, fitshape=(11, 11), aperture_radius=ap_radius, \n",
    "                                              extra_output_cols=('sharpness', 'roundness2'))\n",
    "    result = phot(data)\n",
    "    \n",
    "    toc = time.perf_counter()\n",
    "    \n",
    "    print('Time needed to perform photometry:', '%.2f' % ((toc - tic) / 3600), 'hours')\n",
    "    print('Number of sources detected:', len(result))\n",
    "        \n",
    "    residual_image = phot.get_residual_image()\n",
    "    \n",
    "    # save the residual images as fits file:\n",
    "\n",
    "    if save_residuals:\n",
    "        hdu = fits.PrimaryHDU(residual_image)\n",
    "        hdul = fits.HDUList([hdu])\n",
    "    \n",
    "        residual_outname = 'residual_%s_%s.fits' % (det, filt)\n",
    "\n",
    "        hdul.writeto(os.path.join(res_dir, residual_outname))\n",
    "\n",
    "    # save the output photometry Tables\n",
    "\n",
    "    if save_output:\n",
    "\n",
    "        outname = 'phot_%s_%s.pkl' % (det, filt)\n",
    "        \n",
    "        tab = result.to_pandas()\n",
    "        tab.to_pickle(os.path.join(output_phot_dir, outname))\n",
    "    \n",
    "    return result, residual_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "present-toyota",
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = data\n",
    "\n",
    "output_phot_dir = 'PHOT_OUTPUT/'\n",
    "\n",
    "if not os.path.exists(output_phot_dir):\n",
    "    os.makedirs(output_phot_dir)\n",
    "\n",
    "res_dir = 'RESIDUAL_IMAGES/'\n",
    "\n",
    "if not os.path.exists(res_dir):\n",
    "    os.makedirs(res_dir)\n",
    "\n",
    "if glob.glob(os.path.join(res_dir, 'residual*F560W.fits')):\n",
    "    print('Deleting Residual images from directory')\n",
    "    files = glob.glob(os.path.join(res_dir, 'residual*F560W.fits'))\n",
    "    for file in files:\n",
    "        os.remove(file)\n",
    "\n",
    "psf_phot_results, residual_image = psf_phot(data=data1, det=det, filt=filt, th=10, psf=psf_webbpsf_grid, \n",
    "                                            save_residuals=True, save_output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "absent-confirmation",
   "metadata": {},
   "source": [
    "### 6.1<font color='white'>-</font>PSF photometry output catalog<a class=\"anchor\" id=\"psf_cat\"></a> ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interpreted-minimum",
   "metadata": {},
   "outputs": [],
   "source": [
    "psf_phot_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stock-costs",
   "metadata": {},
   "source": [
    "### 6.2<font color='white'>-</font>Display residual image<a class=\"anchor\" id=\"residual\"></a> ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "partial-satisfaction",
   "metadata": {},
   "outputs": [],
   "source": [
    "#imshow_me_wcolorbar(im[1].data, med-1*sig, med+1*sig, 'Image after masking', 'x [MIRIM pixel]', 'y [MIRIM pixel]', 'MJy sr$^{-1}$', 'binary')\n",
    "imviz = Imviz()\n",
    "imviz.app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tight-condition",
   "metadata": {},
   "outputs": [],
   "source": [
    "imviz.load_data(residual_image,data_label='Residual')\n",
    "imviz.load_data(data1,data_label='Original')\n",
    "viewer = imviz.default_viewer\n",
    "viewer.cuts = '95%'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "growing-season",
   "metadata": {},
   "outputs": [],
   "source": [
    "viewer_2_name='Window 2'\n",
    "viewer_2 = imviz.create_image_viewer(viewer_name=viewer_2_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "answering-picture",
   "metadata": {},
   "outputs": [],
   "source": [
    "imviz.app.add_data_to_viewer(viewer_2_name, 'Residual')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "finished-blond",
   "metadata": {},
   "outputs": [],
   "source": [
    "viewer_2.cuts = '95%'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "iraqi-going",
   "metadata": {},
   "source": [
    "<hr style=\"border:1px solid gray\"> </hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "involved-apartment",
   "metadata": {},
   "source": [
    "<img style=\"float: center;\" src=\"https://raw.githubusercontent.com/spacetelescope/notebooks/master/assets/stsci_pri_combo_mark_horizonal_white_bkgd.png\" alt=\"Space Telescope Logo\" width=\"200px\"/>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc-showcode": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
