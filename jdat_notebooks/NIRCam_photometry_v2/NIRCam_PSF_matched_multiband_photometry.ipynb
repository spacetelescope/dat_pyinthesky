{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NIRCam PSF-matched multiband photometry"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Use case:** Measure galaxy photometry in an extragalactic \"blank\" field. Related to [JDox Science Use Case #22](https://jwst-docs.stsci.edu/near-infrared-camera/nircam-example-science-programs/nircam-deep-field-imaging-with-miri-imaging-parallels).<br>\n",
    "**Data:** JWST simulated NIRCam images from [JADES JWST GTO extragalactic blank field](http://fenrir.as.arizona.edu/jwstmock/).<br>\n",
    "(Williams et al. 2018) https://ui.adsabs.harvard.edu/abs/2018ApJS..236...33W.<br>\n",
    "**Tools:**  photutils, matplotlib.<br>\n",
    "**Cross-intrument:** potentially NIRISS, MIRI.<br>\n",
    "**Documentation:** This notebook is part of a STScI's larger [post-pipeline Data Analysis Tools Ecosystem](https://jwst-docs.stsci.edu/jwst-post-pipeline-data-analysis).<br>\n",
    "\n",
    "## Introduction\n",
    "\n",
    "This notebook uses `photutils` to detect objects/galaxies in NIRCam deep imaging.  Detections are first made in a F200W image, then isophotal photometry is obtained in all 9 filters (F090W, F115W, F150W, F200W, F277W, F335M, F356W, F410M, F444W). The catalog is loaded back in and some simple analysis is performed on the full catalog and on an individual galaxy.\n",
    "\n",
    "The notebook analyzes only the central 1000 x 1000 pixels (30\" x 30\") of the full JADES simulation. These cutouts have been staged at STScI with permission from the authors (Williams et al.).\n",
    "\n",
    "**NOTE:** These JADES images are simulated using [Guitarra](https://github.com/cnaw/guitarra),\n",
    "not [MIRAGE](https://github.com/spacetelescope/mirage).\n",
    "They have different properties and units (e-/s) than JWST pipeline products (MJy/sr).\n",
    "\n",
    "**NOTE:** An exposure map is missing and would improve calculations of flux uncertainties."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from glob import glob\n",
    "import os\n",
    "from copy import deepcopy\n",
    "\n",
    "import astropy  # version 4.2 is required to write magnitudes to ecsv file\n",
    "from astropy.io import fits\n",
    "import astropy.wcs as wcs\n",
    "from astropy.table import QTable, Table\n",
    "import astropy.units as u\n",
    "from astropy.visualization import make_lupton_rgb, SqrtStretch, LogStretch, hist\n",
    "from astropy.visualization.mpl_normalize import ImageNormalize\n",
    "from astropy.convolution import Gaussian2DKernel\n",
    "from astropy.stats import gaussian_fwhm_to_sigma\n",
    "from astropy.coordinates import SkyCoord\n",
    "\n",
    "import photutils\n",
    "# print('photutils', photutils.__version__)\n",
    "from photutils import Background2D, MedianBackground, detect_sources, deblend_sources, source_properties\n",
    "from photutils.utils import calc_total_error\n",
    "\n",
    "from photutils.psf.matching import resize_psf\n",
    "from photutils import CosineBellWindow, create_matching_kernel\n",
    "from astropy.convolution import convolve # , Gaussian2DKernel, Tophat2DKernel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matplotlib setup for plotting\n",
    "There are two versions\n",
    " - `notebook` -- gives interactive plots, but makes the overall notebook a bit harder to scroll\n",
    " - `inline` -- gives non-interactive plots for better overall scrolling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Developer's Notes:*\n",
    "\n",
    "    `%matplotlib notebook` occasionally creates oversized plot; need to rerun cell to get it to settle back down"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "\n",
    "# Use this version for non-interactive plots (easier scrolling of the notebook)\n",
    "# %matplotlib inline\n",
    "\n",
    "# Use this version if you want interactive plots\n",
    "%matplotlib notebook\n",
    "\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "# These gymnastics are needed to make the sizes of the figures\n",
    "# be the same in both the inline and notebook versions\n",
    "%config InlineBackend.print_figure_kwargs = {'bbox_inches': None}\n",
    "\n",
    "mpl.rcParams['savefig.dpi'] = 100\n",
    "mpl.rcParams['figure.dpi'] = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show versions of Python and imported libraries\n",
    "try:\n",
    "    import watermark\n",
    "    %load_ext watermark\n",
    "    # %watermark -n -v -m -g -iv\n",
    "    %watermark -iv -v\n",
    "except ImportError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check PEP 8 style formatting\n",
    "%load_ext pycodestyle_magic\n",
    "%flake8_on --ignore E261,E501,W291,W2,E302,E305"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create list of images to be loaded and analyzed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file_url = 'https://data.science.stsci.edu/redirect/JWST/jwst-data_analysis_tools/nircam_photometry/'\n",
    "\n",
    "filters = 'F090W F115W F150W F200W F277W F335M F356W F410M F444W'.split()\n",
    "\n",
    "# Data images [e-/s], unlike JWST pipeline images that will have units [Myr/sr]\n",
    "image_files = {}\n",
    "for filt in filters:\n",
    "    filename = f'jades_jwst_nircam_goods_s_crop_{filt}.fits'\n",
    "    image_files[filt] = os.path.join(input_file_url, filename)\n",
    "\n",
    "# Weight images (Inverse Variance Maps; IVM)\n",
    "weight_files = {}\n",
    "for filt in filters:\n",
    "    filename = f'jades_jwst_nircam_goods_s_crop_{filt}_wht.fits'\n",
    "    weight_files[filt] = os.path.join(input_file_url, filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load detection image: F200W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filt = 'F200W'\n",
    "infile = image_files[filt]\n",
    "hdu = fits.open(infile)\n",
    "data = hdu[0].data\n",
    "imwcs = wcs.WCS(hdu[0].header, hdu)\n",
    "\n",
    "weight = fits.open(weight_files[filt])[0].data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Report image size and field of view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ny, nx = data.shape\n",
    "# image_pixel_scale = np.abs(hdu[0].header['CD1_1']) * 3600\n",
    "image_pixel_scale = wcs.utils.proj_plane_pixel_scales(imwcs)[0] \n",
    "image_pixel_scale *= imwcs.wcs.cunit[0].to('arcsec')\n",
    "outline = '%d x %d pixels' % (ny, nx)\n",
    "outline += ' = %g\" x %g\"' % (ny * image_pixel_scale, nx * image_pixel_scale)\n",
    "outline += ' (%.2f\" / pixel)' % image_pixel_scale\n",
    "print(outline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create color images (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3 NIRCam short wavelength channel images\n",
    "r = fits.open(image_files['F200W'])[0].data\n",
    "g = fits.open(image_files['F150W'])[0].data\n",
    "b = fits.open(image_files['F090W'])[0].data\n",
    "color_image_short_wavelength = make_lupton_rgb(r, g, b, Q=5, stretch=0.02) # , minimum=-0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3 NIRCam long wavelength channel images\n",
    "r = fits.open(image_files['F444W'])[0].data\n",
    "g = fits.open(image_files['F356W'])[0].data\n",
    "b = fits.open(image_files['F277W'])[0].data\n",
    "\n",
    "color_image_long_wavelength = make_lupton_rgb(r, g, b, Q=5, stretch=0.02) # , minimum=-0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Developer's Note:*\n",
    "\n",
    "    sharex & sharey appear to have some compatibility issues with projection=imwcs\n",
    "\n",
    "    As a workaround, I tried but was unable to turn off yticklabels in the right plot below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(9.5, 4))\n",
    "\n",
    "ax_sw = fig.add_subplot(1, 2, 1, projection=imwcs) # , sharex=True, sharey=True)\n",
    "ax_sw.imshow(color_image_short_wavelength, origin='lower')\n",
    "ax_sw.set_xlabel('Right Ascension')\n",
    "ax_sw.set_ylabel('Declination')\n",
    "ax_sw.set_title('Short Wavelength Channel')\n",
    "\n",
    "ax_lw = fig.add_subplot(1, 2, 2, projection=imwcs, sharex=ax_sw, sharey=ax_sw)\n",
    "ax_lw.imshow(color_image_long_wavelength, origin='lower')\n",
    "ax_lw.set_xlabel('Right Ascension')\n",
    "ax_lw.set_title('Long Wavelength Channel')\n",
    "ax_lw.set_ylabel('')\n",
    "# ax_lw.set(yticklabels=[])  # this didn't work\n",
    "\n",
    "# plt.subplots_adjust(left=0.15)\n",
    "print('Interactive zoom / pan controls both images simultaneously')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detect Sources and Deblend using astropy.photutils\n",
    "https://photutils.readthedocs.io/en/latest/segmentation.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Photutils_Catalog:\n",
    "    def __init__(self, data, weight, imwcs):\n",
    "        self.data = data\n",
    "        self.weight = weight\n",
    "        self.imwcs = imwcs\n",
    "        \n",
    "    def measure_background_map(self, bkg_size=50, filter_size=3, verbose=True):\n",
    "        # Calculate sigma-clipped background in cells of 50x50 pixels, then median filter over 3x3 cells\n",
    "        # For best results, the image should span an integer number of cells in both dimensions (here, 1000=20x50 pixels)\n",
    "        # https://photutils.readthedocs.io/en/stable/background.html\n",
    "        self.background_map = Background2D(self.data, bkg_size, filter_size=filter_size)\n",
    "\n",
    "    def run_detect_sources(self, nsigma, npixels, smooth_fwhm=2, kernel_size=5, \n",
    "                           deblend_levels=32, deblend_contrast=0.001, verbose=True):\n",
    "\n",
    "        # Set detection threshold map as nsigma times RMS above background pedestal\n",
    "        detection_threshold = (nsigma * self.background_map.background_rms) + self.background_map.background\n",
    "\n",
    "        # Before detection, convolve data with Gaussian\n",
    "        smooth_sigma = smooth_fwhm * gaussian_fwhm_to_sigma\n",
    "        smooth_kernel = Gaussian2DKernel(smooth_sigma, x_size=kernel_size, y_size=kernel_size)\n",
    "        smooth_kernel.normalize()\n",
    "\n",
    "        # Detect sources with npixels connected pixels at/above threshold in data smoothed by kernel\n",
    "        # https://photutils.readthedocs.io/en/stable/segmentation.html\n",
    "        self.segm_detect = detect_sources(self.data, detection_threshold, npixels=npixels, filter_kernel=smooth_kernel)\n",
    "\n",
    "        # Deblend: separate connected/overlapping sources\n",
    "        # https://photutils.readthedocs.io/en/stable/segmentation.html#source-deblending\n",
    "        self.segm_deblend = deblend_sources(self.data, self.segm_detect, npixels=npixels, filter_kernel=smooth_kernel,\n",
    "                                            nlevels=deblend_levels, contrast=deblend_contrast)\n",
    "        if verbose:\n",
    "            output = 'Cataloged %d objects' % self.segm_deblend.nlabels\n",
    "            output += ', deblended from %d detections' % self.segm_detect.nlabels\n",
    "            median_threshold = (nsigma * self.background_map.background_rms_median) \\\n",
    "                + self.background_map.background_median\n",
    "            output += ' with %d pixels above %g-sigma threshold' % (npixels, nsigma)\n",
    "            # Background outputs equivalent to those reported by SourceExtractor\n",
    "            output += '\\n'\n",
    "            output += 'Background median %g' % self.background_map.background_median\n",
    "            output += ', RMS %g' % self.background_map.background_rms_median\n",
    "            output += ', threshold median %g' % median_threshold\n",
    "            print(output)\n",
    "\n",
    "    def measure_source_properties(self, exposure_time, local_background_width=24):\n",
    "        # \"effective_gain\" = exposure time map (conversion from data rate units to counts)\n",
    "        # weight = inverse variance map = 1 / sigma_background**2 (without sources)\n",
    "        # https://photutils.readthedocs.io/en/latest/api/photutils.utils.calc_total_error.html\n",
    "        self.exposure_time_map = exposure_time * self.background_map.background_rms_median**2 * self.weight\n",
    "\n",
    "        # Data RMS uncertainty is combination of background RMS and source Poisson uncertainties\n",
    "        background_rms = 1 / np.sqrt(self.weight)\n",
    "        # effective gain parameter required to be positive everywhere (not zero), so adding small value 1e-8\n",
    "        self.data_rms = calc_total_error(self.data, background_rms, self.exposure_time_map+1e-8)\n",
    "\n",
    "        self.catalog = source_properties(self.data-self.background_map.background, self.segm_deblend, wcs=self.imwcs, \n",
    "                                         error=self.data_rms, background=self.background_map.background, \n",
    "                                         localbkg_width=local_background_width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detection_catalog = Photutils_Catalog(data, weight, imwcs)\n",
    "detection_catalog.measure_background_map()\n",
    "detection_catalog.run_detect_sources(nsigma=2, npixels=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measure photometry (and more) in detection image\n",
    "https://photutils.readthedocs.io/en/latest/segmentation.html#centroids-photometry-and-morphological-properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exposure_time = hdu[0].header.get('EXPTIME')  # seconds\n",
    "exposure_time = 49500  # seconds; Adding by hand because it's missing from the image header\n",
    "detection_catalog.measure_source_properties(exposure_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save segmentation map of detected objects\n",
    "segm_hdu = fits.PrimaryHDU(detection_catalog.segm_deblend.data.astype(np.uint32), header=imwcs.to_header())\n",
    "segm_hdu.writeto('JADES_detections_segm.fits', overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show detections alongside images (optional)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Developer's Note:*\n",
    "\n",
    "    Interactive plots zoom / pan all frames simultaneously. (User can zoom in on individual galaxies.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2, 3, sharex=True, sharey=True, figsize=(9.5, 6))\n",
    "# fig, ax = plt.subplots(2, 3, sharex=True, sharey=True, figsize=(9.5, 6), subplot_kw={'projection': imwcs})\n",
    "# For RA,Dec axes instead of pixels, add: , subplot_kw={'projection': imwcs})\n",
    "\n",
    "# Color image\n",
    "ax[0,0].imshow(color_image_short_wavelength, origin='lower')\n",
    "ax[0,0].set_title('Color Image')\n",
    "\n",
    "# Data\n",
    "norm = ImageNormalize(stretch=SqrtStretch(), vmin=0)\n",
    "ax[0,1].imshow(data, origin='lower', cmap='Greys_r', norm=norm)\n",
    "ax[0,1].set_title('Detection Image F200W')\n",
    "\n",
    "# Segmentation map\n",
    "cmap = detection_catalog.segm_deblend.make_cmap(seed=12345)  # ERROR\n",
    "ax[0,2].imshow(detection_catalog.segm_deblend, origin='lower', cmap=cmap, interpolation='none')\n",
    "ax[0,2].set_title('Detections (Segmentation Image)')\n",
    "\n",
    "# norm = ImageNormalize(stretch=SqrtStretch())\n",
    "# ax[1,0].imshow(weight, origin='lower', cmap='Greys_r', vmin=0)\n",
    "# ax[1,0].set_title('Weight Image F200W')\n",
    "\n",
    "ax[1,0].imshow(detection_catalog.exposure_time_map, origin='lower', cmap='Greys_r', vmin=0)\n",
    "ax[1,0].set_title('Exposure Time Map')\n",
    "\n",
    "# ax[1,0].imshow(background_map.background, origin='lower', cmap='Greys_r')\n",
    "# ax[1,0].set_title('Background Pedestal')\n",
    "\n",
    "# RMS\n",
    "# norm = ImageNormalize()\n",
    "vmin, vmax = 0.001, 0.0035\n",
    "ax[1,1].imshow(detection_catalog.background_map.background_rms, origin='lower', vmin=vmin, vmax=vmax)\n",
    "ax[1,1].set_title('Background RMS')\n",
    "\n",
    "# Total error including Poisson noise\n",
    "ax[1,2].imshow(detection_catalog.data_rms, origin='lower', vmin=vmin, vmax=vmax)\n",
    "ax[1,2].set_title('RMS + Poisson noise')\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "print('Interactive zoom / pan controls all images simultaneously')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View all measured quantities in detection image (optional)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Only keep some quantities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = 'id xcentroid ycentroid sky_centroid area semimajor_axis_sigma semiminor_axis_sigma'.split()\n",
    "columns += 'ellipticity orientation gini'.split()\n",
    "columns += 'kron_radius local_background source_sum source_sum_err kron_flux kron_fluxerr'.split()\n",
    "# columns += 'source_sum source_sum_err kron_flux kron_fluxerr kron_radius local_background'.split()\n",
    "\n",
    "source_table = detection_catalog.catalog.to_table(columns=columns)\n",
    "source_table.rename_column('semimajor_axis_sigma', 'a')\n",
    "source_table.rename_column('semiminor_axis_sigma', 'b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# source_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert measured fluxes (data units) to magnitudes\n",
    "\n",
    "https://docs.astropy.org/en/stable/units/\n",
    "\n",
    "https://docs.astropy.org/en/stable/units/equivalencies.html#photometric-zero-point-equivalency\n",
    "\n",
    "https://docs.astropy.org/en/stable/units/logarithmic_units.html#logarithmic-units"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Developer note:*\n",
    "    \n",
    "    flux units can be automatically converted to magnitude units\n",
    "    but flux uncertainties *cannot* be automatically converted to magnitude uncertainties\n",
    "    thus I wrote this function to do so\n",
    "    \n",
    "    Note magnitude uncertainties for detections should probably be u.mag instead of u.ABmag\n",
    "    but magnitude uncertainties for non-detections quote u.ABmag upper limits\n",
    "    They need to be the same, so we go with u.ABmag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# not detected: mag =  99; magerr = 1-sigma upper limit assuming zero flux\n",
    "# not observed: mag = -99; magerr = 0\n",
    "def fluxes2mags(flux, fluxerr):\n",
    "    nondet = flux < 0  # Non-detection if flux is negative\n",
    "    unobs = (fluxerr <= 0) + (fluxerr == np.inf)  # Unobserved if flux uncertainty is negative or infinity\n",
    "\n",
    "    mag = flux.to(u.ABmag)\n",
    "    magupperlimit = fluxerr.to(u.ABmag) # 1-sigma upper limit if flux=0\n",
    "\n",
    "    mag = np.where(nondet, 99 * u.ABmag, mag)\n",
    "    mag = np.where(unobs, -99 * u.ABmag, mag)\n",
    "\n",
    "    magerr = 2.5 * np.log10(1 + fluxerr/flux) \n",
    "    magerr = magerr.value * u.ABmag\n",
    "\n",
    "    magerr = np.where(nondet, magupperlimit, magerr)\n",
    "    magerr = np.where(unobs, 0 * u.ABmag, magerr)\n",
    "    \n",
    "    return mag, magerr\n",
    "\n",
    "# Includes features I couldn't find in astropy:\n",
    "# mag = 99 / -99 for non-detections / unobserved\n",
    "# flux uncertainties -> mag uncertainties"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiband photometry using isophotal apertures defined in detection image\n",
    "(Similar to running SourceExtractor in double-image mode)  \n",
    "(No PSF corrections just yet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filters = 'F090W F115W F150W F200W F277W F335M F356W F410M F444W'.split()\n",
    "for filt in filters:\n",
    "    infile = image_files[filt]\n",
    "    print(filt)\n",
    "    print(infile)\n",
    "    print(weight_files[filt])\n",
    "    hdu = fits.open(infile)\n",
    "    data = hdu[0].data\n",
    "    zeropoint = hdu[0].header['ABMAG'] * u.ABmag\n",
    "    weight = fits.open(weight_files[filt])[0].data\n",
    "\n",
    "    # exposure_time = hdu[0].header.get('EXPTIME')  # seconds    \n",
    "\n",
    "    filter_catalog = Photutils_Catalog(data, weight, imwcs)\n",
    "    filter_catalog.measure_background_map()\n",
    "    # Median background (equivalent to that reported by Source Extractor)\n",
    "    # filter_catalog.background_map.background_rms_median\n",
    "\n",
    "    # Measure photometry in this filter for objects detected in detected image\n",
    "    # segmentation map will define isophotal apertures\n",
    "    filter_catalog.segm_deblend = detection_catalog.segm_deblend\n",
    "    filter_catalog.measure_source_properties(exposure_time)\n",
    "        \n",
    "    # Convert measured fluxes to fluxes in nJy and to AB magnitudes\n",
    "    filter_table = filter_catalog.catalog.to_table()\n",
    "    source_table[filt+'_flux'] = flux = filter_table['source_sum'] * zeropoint.to(u.nJy)\n",
    "    source_table[filt+'_fluxerr'] = fluxerr = filter_table['source_sum_err'] * zeropoint.to(u.nJy)\n",
    "\n",
    "    mag, magerr = fluxes2mags(flux, fluxerr)\n",
    "    source_table[filt+'_mag'] = mag\n",
    "    source_table[filt+'_magerr'] = magerr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View complete results (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#source_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load PSFs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PSF tar files available on JDox:  \n",
    "https://jwst-docs.stsci.edu/near-infrared-camera/nircam-predicted-performance/nircam-point-spread-functions#NIRCamPointSpreadFunctions-SimulatedNIRCamPSFs  \n",
    "PSFs_SW_filters (short wavelength channel): https://stsci.box.com/s/s2lepxr9086gq4sogr3kwftp54n1c5vl  \n",
    "PSFs_LW_filters (long wavelength channel): https://stsci.box.com/s/gzl7blxb1k3p4n66gs7jvt7xorfrotyb  \n",
    "\n",
    "Each FITS file contains:  \n",
    "– hdu[0]: a 4x oversampled PSF  \n",
    "– hdu[1]: PSF at detector pixel scale (0.031\" and 0.063\" in the short and long wavelength channels, respectively)  \n",
    "This notebook will use the latter: PSF at detector pixel scale. We find no advantage to the former for this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PSF_inputs = {}\n",
    "PSF_images = {}\n",
    "\n",
    "detector_pixel_scales = {'SW': 0.031, 'LW': 0.063}\n",
    "\n",
    "PSF_url = os.path.join(input_file_url, 'NIRCam_PSFs')\n",
    "\n",
    "for i, filt in enumerate(filters):\n",
    "    lam = int(filt[1:4]) / 100\n",
    "    if lam < 2.4:\n",
    "        channel = 'SW'\n",
    "    else:\n",
    "        channel = 'LW'\n",
    "\n",
    "    # Load PSF\n",
    "    PSF_file = 'PSF_%scen_G5V_fov299px_ISIM41.fits' % filt\n",
    "    # PSF_file = os.path.join('NIRCam_PSFs_' + channel, PSF_file)\n",
    "    PSF_file = os.path.join(PSF_url, PSF_file)\n",
    "\n",
    "    print(PSF_file)\n",
    "    PSF_hdu = fits.open(PSF_file)\n",
    "    PSF_inputs[filt] = data = PSF_hdu[1].data  # 2nd extension is at pixel scale (not oversampled)\n",
    "    # imwcs = wcs.WCS(hdu[0].header, hdu)\n",
    "    ny, nx = data.shape\n",
    "    \n",
    "    # Resize from detector pixel scale to image pixel scale (here 0.03\" / pix)\n",
    "    detector_pixel_scale = detector_pixel_scales[channel]\n",
    "    ny_resize = ny * detector_pixel_scale / image_pixel_scale  # Assume square PSF (ny = nx)\n",
    "    ny_resize = np.round(ny_resize)\n",
    "    ny_resize = np.int((ny_resize // 2) * 2 + 1)  # Make it an odd number of pixels to ensure PSF is centered\n",
    "    PSF_pixel_scale = ny_resize / ny * image_pixel_scale    \n",
    "    PSF_image = resize_psf(PSF_inputs[filt], PSF_pixel_scale, image_pixel_scale)  # Resize PSF here\n",
    "    r = (ny_resize - ny) // 2\n",
    "    PSF_images[filt] = PSF = PSF_image[r:-r, r:-r]  # Trim to same size as input PSFs\n",
    "    # print(filt, ny, ny_resize, PSF_image.shape, PSF_images[filt].shape, PSF_pixel_scale)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PSF Matching \n",
    "\n",
    "https://photutils.readthedocs.io/en/stable/psf_matching.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Determine PSF convolution kernels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show PSFs (optional)\n",
    "\n",
    "fig, ax = plt.subplots(1, len(filters), figsize=(9.5, 1.5), sharex=True, sharey=True)\n",
    "\n",
    "r = 15\n",
    "for i, filt in enumerate(filters):\n",
    "    data = PSF_images[filt]\n",
    "    ny, nx = data.shape\n",
    "    yc = ny // 2\n",
    "    xc = nx // 2\n",
    "    stamp = data[yc-r:yc+r+1, xc-r:xc+r+1]\n",
    "    norm = ImageNormalize(stretch=LogStretch())  # scale each filter individually\n",
    "    ax[i].imshow(stamp, cmap='Greys_r', norm=norm, origin='lower')\n",
    "    ax[i].set_title(filt.upper())\n",
    "    ax[i].axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PSF_kernels = {}\n",
    "reference_filter = 'F200W'\n",
    "reference_PSF = PSF_images[reference_filter]\n",
    "i_reference = filters.index(reference_filter)\n",
    "window = CosineBellWindow(alpha=0.35)\n",
    "for filt in filters[i_reference+1:]:\n",
    "    PSF_kernels[filt] = PSF_matching_kernel = create_matching_kernel(reference_PSF, PSF_images[filt], window=window)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolve PSFs and compare to actual (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PSFs_convolved = {}\n",
    "for filt in filters[i_reference+1:]:\n",
    "    PSF = PSF_images[reference_filter][yc-r:yc+r+1, xc-r:xc+r+1]\n",
    "    kernel = PSF_kernels[filt][yc-r:yc+r+1, xc-r:xc+r+1]\n",
    "    PSFs_convolved[filt] = convolve(PSF, kernel)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def radial_profile(PSF):\n",
    "    data = PSF\n",
    "    ny, nx = data.shape\n",
    "    yc = ny // 2\n",
    "    xc = nx // 2\n",
    "    y, x = np.indices(data.shape)\n",
    "    rr = np.sqrt((x-xc)**2 + (y-yc)**2)\n",
    "    ii = np.argsort(rr.flat)\n",
    "    rr = rr.flat[ii]\n",
    "    yy = data.flat[ii]\n",
    "    return rr, yy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpl_colors = plt.rcParams['axes.prop_cycle'].by_key()['color']\n",
    "plot_colors = [mpl_colors[i] for i in (0, 6, 1)]\n",
    "\n",
    "plot_filters = filters[i_reference:]\n",
    "ncolumns = len(plot_filters)\n",
    "\n",
    "fig, ax = plt.subplots(4, ncolumns, figsize=(9.5, 6)) # , sharex=True, sharey=True)\n",
    "\n",
    "for i, filt in enumerate(plot_filters):\n",
    "    # Input PSF on top row\n",
    "    ny, nx = PSF_images[filt].shape\n",
    "    yc = ny // 2\n",
    "    xc = nx // 2    \n",
    "    stamp = PSF_images[filt][yc-r:yc+r+1, xc-r:xc+r+1]\n",
    "    norm = ImageNormalize(stretch=SqrtStretch())  # scale each stamp individually\n",
    "    ax[0,i].imshow(stamp, cmap='Greys_r', norm=norm, origin='lower')\n",
    "    ax[0,i].set_title(filt.upper())\n",
    "\n",
    "    rr, yy = radial_profile(stamp)\n",
    "    ax[3,i].plot(rr, yy, color=plot_colors[0], alpha=0.7)\n",
    "    ax[3,i].set_xlim(0, r)\n",
    "    ax[3,i].set_ylim(0, 0.05)\n",
    "\n",
    "    for j in range(4):\n",
    "        ax[j,i].get_xaxis().set_ticks([])\n",
    "        ax[j,i].get_yaxis().set_ticks([])\n",
    "\n",
    "    if i == 0:\n",
    "        # Plot F200W profile everywhere for comparison\n",
    "        for icolumn in range(ncolumns):\n",
    "            ax[3,icolumn].plot(rr, yy, color='g', lw=0) # hidden with lw=0\n",
    "        continue\n",
    "        \n",
    "    # Kernels\n",
    "    kernel = PSF_kernels[filt][yc-r:yc+r+1, xc-r:xc+r+1]\n",
    "    norm = ImageNormalize(stretch=SqrtStretch())  # scale each stamp individually\n",
    "    ax[1,i].imshow(kernel, cmap='Greys_r', norm=norm, origin='lower')\n",
    "    \n",
    "    rr, yy = radial_profile(kernel)\n",
    "    ax[3,i].plot(rr, yy, color=plot_colors[1], alpha=0.7, lw=0) # hidden with lw=0\n",
    "\n",
    "    # Convolved PSFs\n",
    "    stamp = PSFs_convolved[filt]\n",
    "    norm = ImageNormalize(stretch=SqrtStretch())  # scale each stamp individually\n",
    "    ax[2,i].imshow(stamp, cmap='Greys_r', norm=norm, origin='lower')\n",
    "\n",
    "    rr, yy = radial_profile(stamp)\n",
    "    ax[3,i].plot(rr, yy, color=plot_colors[2], alpha=0.7)\n",
    "\n",
    "ax[0,0].set_ylabel('PSF', color=plot_colors[0])\n",
    "ax[1,0].set_ylabel('Kernel', color=plot_colors[1])\n",
    "ax[2,0].set_ylabel('Convolved', color=plot_colors[2])\n",
    "ax[3,0].set_ylabel('Radial Profiles')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note the convolved PSF radial profiles don't match the target PSFs as well as you might expect.  \n",
    "But they get the job done, as we'll see below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolve F200W detection image to Long Wavelength PSFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "reference_image_hdu = fits.open(image_files[reference_filter])\n",
    "reference_image_data = reference_image_hdu[0].data[:]\n",
    "\n",
    "for filt in filters[i_reference+1:]:\n",
    "    output_filter = filt\n",
    "    output_image = 'jades_convolved_%s_to_%s.fits' % (reference_filter, output_filter)\n",
    "    if os.path.exists(output_image):\n",
    "        print(output_image, 'EXISTS')\n",
    "    else:\n",
    "        print(output_filter + '...')\n",
    "        PSF_kernel = PSF_kernels[filt][yc-r:yc+r+1, xc-r:xc+r+1]\n",
    "        convolved_image = convolve(reference_image_data, PSF_kernel)\n",
    "        reference_image_hdu[0].data = convolved_image\n",
    "        print('SAVING %s' % output_image)\n",
    "        reference_image_hdu.writeto(output_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiband photometry in convolved images "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for filt in filters[i_reference+1:]:\n",
    "    infile = 'jades_convolved_%s_to_%s.fits' % (reference_filter, output_filter)\n",
    "    print(filt)\n",
    "    print(infile)\n",
    "    print(weight_files[filt])\n",
    "    hdu = fits.open(infile)\n",
    "    data = hdu[0].data\n",
    "    zeropoint = hdu[0].header['ABMAG'] * u.ABmag  # zeropoint\n",
    "    weight = fits.open(weight_files[filt])[0].data\n",
    "    # exposure_time = hdu[0].header.get('EXPTIME')  # seconds    \n",
    "    \n",
    "    filter_catalog = Photutils_Catalog(data, weight, imwcs)\n",
    "    filter_catalog.measure_background_map()\n",
    "    # Median background (equivalent to that reported by Source Extractor)\n",
    "    # filter_catalog.background_map.background_rms_median\n",
    "\n",
    "    # Measure photometry in this filter for objects detected in detected image\n",
    "    # segmentation map will define isophotal apertures\n",
    "    filter_catalog.segm_deblend = detection_catalog.segm_deblend\n",
    "    filter_catalog.measure_source_properties(exposure_time)\n",
    "\n",
    "    # Convert measured fluxes to fluxes in nJy\n",
    "    filter_table = filter_catalog.catalog.to_table()\n",
    "    source_table['convolved_to_'+filt+'_flux'] = flux = filter_table['source_sum'] * zeropoint.to(u.nJy)\n",
    "    source_table['convolved_to_'+filt+'_fluxerr'] = fluxerr = filter_table['source_sum_err'] * zeropoint.to(u.nJy)\n",
    "\n",
    "    # Convert measured fluxes to AB magnitudes\n",
    "    mag, magerr = fluxes2mags(flux, fluxerr)\n",
    "    source_table['convolved_to_'+filt+'_mag'] = mag\n",
    "    source_table['convolved_to_'+filt+'_magerr'] = magerr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# source_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Magnitude corrections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PSF corrections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.stsci.edu/~dcoe/ColorPro/color\n",
    "\n",
    "# filt_mag_corrected = det_mag_auto + (filt_mag_iso - det_blurry_mag_iso)\n",
    "\n",
    "#                    = (det_mag_iso + mag_kroncor) + (det_mag_auto - det_blurry_mag_iso)\n",
    "\n",
    "#                    = filt_mag_iso + (det_mag_auto - det_blurry_mag_iso)\n",
    "#                    = filt_mag_iso + magnitude_corrections\n",
    "\n",
    "corrected_table = deepcopy(source_table) # copy to new table, which will include PSF-corrections\n",
    "\n",
    "reference_magnitudes = corrected_table[reference_filter+'_mag']  # det_mag_auto\n",
    "\n",
    "for filt in filters[i_reference+1:]:\n",
    "    blurred_magnitudes = corrected_table['convolved_to_'+filt+'_mag']\n",
    "    magnitude_corrections = reference_magnitudes - blurred_magnitudes\n",
    "    filter_magnitudes = corrected_table[filt+'_mag']\n",
    "    corrected_magnitudes = filter_magnitudes + magnitude_corrections\n",
    "    good_magnitudes = np.less(filter_magnitudes.value, 90) * np.greater(filter_magnitudes.value, 0)\n",
    "    corrected_magnitudes = np.where(good_magnitudes, corrected_magnitudes, filter_magnitudes)\n",
    "\n",
    "    reference_fluxes = corrected_table[reference_filter+'_flux']\n",
    "    flux_corrections = 10 ** (-0.4 * magnitude_corrections.value)\n",
    "    flux_corrections = np.where(good_magnitudes, flux_corrections, 1)\n",
    "    filter_fluxes = corrected_table[filt+'_flux']\n",
    "    corrected_fluxes = filter_fluxes * flux_corrections\n",
    "\n",
    "    corrected_table[filt+'_flux'] = corrected_fluxes\n",
    "    corrected_table[filt+'_mag'] = corrected_magnitudes\n",
    "    corrected_table[filt+'_flux_PSFcor'] = flux_corrections\n",
    "    magnitude_corrections = magnitude_corrections.value * u.mag  # convert mag(1) to mag units to enable ecsv loading\n",
    "    corrected_table[filt+'_mag_PSFcor'] = magnitude_corrections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kron vs. Isophotal aperture corrections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAG_AUTO - MAG_ISO\n",
    "# Important: colors have mag units, not ABmag\n",
    "\n",
    "reference_flux_auto = source_table['kron_flux']\n",
    "reference_flux_iso = source_table['source_sum']\n",
    "kron_flux_corrections = reference_flux_auto / reference_flux_iso\n",
    "kron_mag_corrections = -2.5 * np.log10(kron_flux_corrections)\n",
    "kron_mag_corrections = kron_mag_corrections * u.mag\n",
    "corrected_table['mag_Kron_cor'] = kron_mag_corrections\n",
    "\n",
    "for filt in filters:\n",
    "    corrected_table[filt+'_flux'] *= kron_flux_corrections\n",
    "    corrected_table[filt+'_mag'] += kron_mag_corrections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reformat output catalog for readability (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_table = deepcopy(corrected_table) # copy to new table, which will include PSF-corrections\n",
    "\n",
    "# Remove units (pixels) from area\n",
    "output_table['area'] = output_table['area'].value.astype(int)\n",
    "\n",
    "# Replace sky_centroid with ra, dec\n",
    "output_table['ra'] = output_table['sky_centroid'].ra.degree\n",
    "output_table['dec'] = output_table['sky_centroid'].dec.degree\n",
    "\n",
    "columns = list(output_table.columns)\n",
    "columns = columns[:3] + ['ra', 'dec'] + columns[4:-2]\n",
    "\n",
    "for i, column in enumerate(columns):\n",
    "    if column.startswith('source'):\n",
    "        break\n",
    "\n",
    "columns = columns[:i]\n",
    "\n",
    "columns.append('mag_Kron_cor')\n",
    "\n",
    "for filt in filters:\n",
    "    columns.append(filt+'_flux')\n",
    "    columns.append(filt+'_fluxerr')\n",
    "    columns.append(filt+'_mag')\n",
    "    columns.append(filt+'_magerr')\n",
    "    column = filt+'_flux_PSFcor'\n",
    "    if column in list(corrected_table.columns):\n",
    "        columns.append(column)\n",
    "        columns.append(filt+'_mag_PSFcor')\n",
    "        \n",
    "output_table = output_table[columns]\n",
    "\n",
    "for column in columns:\n",
    "    output_table[column].info.format = '.4f'\n",
    "\n",
    "output_table['ra'].info.format = '11.7f'\n",
    "output_table['dec'].info.format = ' 11.7f'\n",
    "\n",
    "output_table['id'].info.format = 'd'\n",
    "output_table['area'].info.format = 'd'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_table.write('JADES_photometry.ecsv', overwrite=True)\n",
    "output_table.write('JADES_photometry.cat', format='ascii.fixed_width_two_line', delimiter=' ', overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !cat JADES_photometry.cat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start new session and analyze results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load catalog and segmentation map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Developer's Note:*\n",
    "\n",
    "    In Astropy 4.2, magnitudes may now be saved in ecsv files (#9933).\n",
    "    Unfortunately, it appears they cannot be read back out.\n",
    "    You see, it knows how to *take* the reservation, it just doesn't know how to *hold* the reservation.\n",
    "\n",
    "    https://docs.astropy.org/en/stable/changelog.html#id75\n",
    "    https://github.com/astropy/astropy/pull/9933"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Catalog: ecsv format preserves units for loading in Python notebooks\n",
    "tbl = QTable.read('JADES_photometry.ecsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reconstitute filter list\n",
    "filters = []\n",
    "for param in tbl.columns:\n",
    "    if param[-4:] == '_mag':\n",
    "        filters.append(param[:-4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Segmentation map\n",
    "segmfile = 'JADES_detections_segm.fits'\n",
    "segm = fits.open(segmfile)[0].data\n",
    "segm = photutils.segmentation.SegmentationImage(segm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot F200W vs. F090W magnitudes and look for dropouts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Developer Notes:*\n",
    "\n",
    "    I would like to hover over each data point and have its id number appear \n",
    "    (ideally as a tooltip, or perhaps at bottom right after the x,y coordinates)\n",
    "\n",
    "    I couldn't figure out how to do that, so instead I used \"text\" to write the id numbers on the plot.\n",
    "    Note that \"plot\" can handle the units, but \"text\" seems to be incompatible with units.\n",
    "    \n",
    "    As is, the output looks awful, but I can make out that I'm interested in object #258 at left."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import mplcursors\n",
    "# Would love a better solution here!\n",
    "\n",
    "mag1 = source_table['F090W_mag']\n",
    "mag2 = source_table['F200W_mag']\n",
    "\n",
    "# Only plot detections in F200W\n",
    "det2 = (0*u.ABmag < mag2) & (mag2 < 90*u.ABmag)\n",
    "\n",
    "mag1 = mag1[det2]\n",
    "mag2 = mag2[det2]\n",
    "ids = source_table['id'][det2]\n",
    "\n",
    "plt.figure(figsize=(8, 4))\n",
    "\n",
    "plt.plot(mag1, mag2, '.')\n",
    "\n",
    "for i in range(len(mag1)):\n",
    "    # plt.text(mag1[i], mag2[i], ids[i])  # doesn't work; text is incompatible with units\n",
    "    plt.text(mag1[i].value, mag2[i].value, ids[i])\n",
    "\n",
    "plt.xlabel('F090W AB magnitude')\n",
    "plt.ylabel('F200W AB magnitude')\n",
    "\n",
    "plt.xlim(plt.xlim()[::-1])\n",
    "plt.ylim(plt.ylim()[::-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Could select object by position\n",
    "# x, y = 905, 276\n",
    "# id = segm.data[y,x]\n",
    "\n",
    "# Select by ID number\n",
    "id = 258 # F090W dropout\n",
    "index = segm.get_index(id)\n",
    "output_obj = tbl[index]\n",
    "output_obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_obj['F200W_mag']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "segmobj = segm[segm.get_index(id)]\n",
    "segmobj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2, len(filters)+1, figsize=(9.5, 3.5), sharex=True, sharey=True)\n",
    "\n",
    "ax[0, 0].imshow(color_image_short_wavelength[segmobj.bbox.slices], origin='lower', extent=segmobj.bbox.extent)\n",
    "ax[0, 0].set_title('Color')\n",
    "\n",
    "cmap = segm.make_cmap(seed=12345)  # ERROR\n",
    "ax[1, 0].imshow(segm.data[segmobj.bbox.slices], origin='lower', extent=segmobj.bbox.extent, cmap=cmap,\n",
    "                interpolation='nearest')\n",
    "ax[1, 0].set_title('Segment')\n",
    "\n",
    "for i in range(1, len(filters)+1):\n",
    "    filt = filters[i-1]\n",
    "\n",
    "    # Show data on top row\n",
    "    data = fits.open(image_files[filt])[0].data\n",
    "    stamp = data[segmobj.bbox.slices]\n",
    "    norm = ImageNormalize(stretch=SqrtStretch())  # scale each filter individually\n",
    "    ax[0, i].imshow(stamp, extent=segmobj.bbox.extent, cmap='Greys_r', norm=norm, origin='lower')\n",
    "    ax[0, i].set_title(filt.upper())\n",
    "\n",
    "    # Show weights on bottom row\n",
    "    weight = fits.open(weight_files[filt])[0].data\n",
    "    stamp = weight[segmobj.bbox.slices]\n",
    "    # set black to zero weight (no exposure time / bad pixel)\n",
    "    ax[1, i].imshow(stamp, extent=segmobj.bbox.extent, vmin=0, cmap='Greys_r', origin='lower')\n",
    "\n",
    "ax[0, 0].set_ylabel('Data')\n",
    "ax[1, 0].set_ylabel('Weight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Color-Magnitude Diagram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# import mplcursors\n",
    "# Would love a better solution here!\n",
    "\n",
    "filt1, filt2 = 'F200W F444W'.split()\n",
    "\n",
    "mag1 = tbl[filt1+'_mag'].value\n",
    "mag2 = tbl[filt2+'_mag'].value\n",
    "\n",
    "# Only plot detections\n",
    "det1 = (0 < mag1) & (mag1 < 90)\n",
    "det2 = (0 < mag2) & (mag2 < 90)\n",
    "det = det1 * det2\n",
    "\n",
    "mag1 = mag1[det]\n",
    "mag2 = mag2[det]\n",
    "\n",
    "plt.figure(figsize=(8, 4))\n",
    "\n",
    "plt.plot(mag2, mag1-mag2, '.')\n",
    "\n",
    "plt.xlim(plt.xlim()[::-1])\n",
    "\n",
    "plt.xlabel(filt2 + ' AB magnitude')\n",
    "plt.ylabel(filt1 + '  $-$  ' + filt2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Input simulation JADES JAGUAR catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 0:\n",
    "    # Already performed this step\n",
    "    # Cropped 302,515 simulated galaxies down to 653 in the smaller images used in this demo    \n",
    "    full_simulated_catalog = Table.read('JADES_SF_mock_r1_v1.1.fits.gz')\n",
    "\n",
    "    RArange = 53.16879, 53.1782\n",
    "    DECrange = -27.805394, -27.797069\n",
    "\n",
    "    good1 = simcat['RA'] > RArange[0]\n",
    "    good2 = simcat['RA'] < RArange[1]\n",
    "    good3 = simcat['DEC'] > DECrange[0]\n",
    "    good4 = simcat['DEC'] < DECrange[1]\n",
    "    all_good = good1 * good2 * good3 * good4\n",
    "\n",
    "    simulated_catalog = full_simulated_catalog[all_good]\n",
    "else:\n",
    "    # Load cropped catalog\n",
    "    input_catalog_file = os.path.join(input_file_url, 'JADES_SF_mock_r1_v1.1_crop.fits.gz')\n",
    "    simulated_catalog = Table.read(input_catalog_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Match objects to photutils catalog\n",
    "# https://docs.astropy.org/en/stable/coordinates/matchsep.html\n",
    "\n",
    "coordsim = SkyCoord(ra=simulated_catalog['RA']*u.degree, dec=simulated_catalog['DEC']*u.degree)\n",
    "coorddet = SkyCoord(ra=tbl['ra']*u.degree, dec=tbl['dec']*u.degree)  # tbl['sky_centroid'] if saved in table\n",
    "idx, d2d, d3d = coorddet.match_to_catalog_sky(coordsim)  # Match photutils to input catalog\n",
    "\n",
    "# Only keep close matches\n",
    "d = d2d / u.degree * 3600  # arcsec\n",
    "goodmatch = d < 0.036\n",
    "\n",
    "simid = simulated_catalog[idx]['ID']\n",
    "simid = np.where(goodmatch, simid, -1)\n",
    "\n",
    "zsim = simulated_catalog[idx]['redshift']\n",
    "zsim = np.where(goodmatch, zsim, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input vs. Output Color\n",
    "\n",
    "filt1, filt2 = 'F200W F444W'.split()\n",
    "\n",
    "input_flux1 = simulated_catalog['NRC_%s_fnu' % filt1][idx][goodmatch]\n",
    "input_flux2 = simulated_catalog['NRC_%s_fnu' % filt2][idx][goodmatch]\n",
    "\n",
    "input_mag1 = (input_flux1 * u.nJy).to(u.ABmag).value\n",
    "input_mag2 = (input_flux2 * u.nJy).to(u.ABmag).value\n",
    "\n",
    "\n",
    "output_mag1 = tbl[filt1 + '_mag'][goodmatch].value\n",
    "output_mag2 = tbl[filt2 + '_mag'][goodmatch].value\n",
    "\n",
    "# Only plot detections\n",
    "det1 = (0 < output_mag1) & (output_mag1 < 90)\n",
    "det2 = (0 < output_mag2) & (output_mag2 < 90)\n",
    "det = det1 * det2\n",
    "\n",
    "output_mag1 = output_mag1[det]\n",
    "output_mag2 = output_mag2[det]\n",
    "\n",
    "input_color = input_mag1 - input_mag2\n",
    "output_color = output_mag1 - output_mag2\n",
    "\n",
    "output_mag1_uncor = output_mag1\n",
    "output_mag2_uncor = output_mag2 - tbl[filt2+'_mag_PSFcor'][goodmatch][det].value\n",
    "output_color_uncor = output_mag1_uncor - output_mag2_uncor\n",
    "\n",
    "plot_min, plot_max = -1, 1\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "plt.plot(input_color, output_color_uncor, 'r.', alpha=0.5, label='uncorrected')\n",
    "plt.plot(input_color, output_color, 'bo', alpha=0.5, label='PSF corrected')\n",
    "\n",
    "plt.plot([plot_min, plot_max], [plot_min, plot_max])\n",
    "\n",
    "plt.xlabel('Input  ' + filt1 + '  $-$  ' + filt2 + '  (mag)')\n",
    "plt.ylabel('Output  ' + filt1 + '  $-$  ' + filt2 + '  (mag)')\n",
    "plt.title('JADES photometry colors: simulated vs. photutils')\n",
    "plt.legend()\n",
    "# plt.savefig('JADES_color_%s-%s.png' % (filt1, filt2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot Spectral Energy Distribution (SED) for one object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_obj = simulated_catalog[idx][index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Measured flux does not recover total input flux\n",
    "# Given known simulation input, determine what fraction of the flux was recovered\n",
    "# Use this to scale measured SED to input SED for comparison, plotted below\n",
    "\n",
    "input_fluxes = np.array([input_obj['NRC_%s_fnu' % filt] for filt in filters])\n",
    "output_fluxes = np.array([output_obj[filt+'_flux'].value for filt in filters])\n",
    "output_flux_errs = np.array([output_obj[filt+'_fluxerr'].value for filt in filters])\n",
    "\n",
    "# Benitez+00 Equations 8 & 9\n",
    "FOT = np.sum(input_fluxes * output_fluxes / output_flux_errs**2)\n",
    "FTT = np.sum(input_fluxes**2 / output_flux_errs**2)\n",
    "flux_scale_factor = FOT / FTT  # a_m\n",
    "flux_scale_factor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Developer's Notes:*\n",
    "\n",
    "    Ideally, the secondary axis should know how to convert between units.\n",
    "    As a workaround, I wrote functions and fed them in.\n",
    "\n",
    "    Even then, this only works so long as fluxes are positive.\n",
    "    Clipping all fluxes to positive values doesn't work either.\n",
    "\n",
    "    I would like to automatically scale the y limits ignoring the input_fluxes.\n",
    "    Instead, for now I just hard-coded a range that works for this example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "flux_factor = 1 / flux_scale_factor\n",
    "for i, filt in enumerate(filters):\n",
    "    input_flux = input_obj['NRC_%s_fnu' % filt]    \n",
    "    output_flux = output_obj[filt+'_flux'].value\n",
    "    output_flux_err = output_obj[filt+'_fluxerr'].value\n",
    "\n",
    "    lam = int(filt[1:4]) / 100\n",
    "    label = ['input fluxes', None][i > 0]\n",
    "    plt.plot(lam, input_flux, marker='.', c=mpl_colors[0], label=label)\n",
    "    label = ['measured PSF-corrected fluxes $\\\\times$ %.1f' % flux_factor, None][i > 0]\n",
    "    plt.errorbar(lam, output_flux*flux_factor, output_flux_err*flux_factor, marker='s', \n",
    "                 c=mpl_colors[1], alpha=0.5, label=label)\n",
    "    \n",
    "    PSFcor_column = filt+'_flux_PSFcor'\n",
    "    if PSFcor_column in list(output_obj.columns):\n",
    "        output_flux_uncor = output_flux / output_obj[PSFcor_column]\n",
    "        label = ['measured uncorrected fluxes $\\\\times$ %.1f' % flux_factor, None][i > i_reference+1]\n",
    "        plt.errorbar(lam, output_flux_uncor * flux_factor, output_flux_err*flux_factor, marker='s', \n",
    "                     c='r', alpha=0.5, label=label)\n",
    "\n",
    "plt.axhline(0, c='k', ls=':')\n",
    "plt.xlim(0, 5)\n",
    "plt.xlabel('Wavelength ($\\\\mu$m)')\n",
    "plt.ylabel('Flux (nJy)')\n",
    "plt.ylim(10, 70)  # hardcoded for this object\n",
    "plt.semilogy()\n",
    "ax.yaxis.set_major_formatter(ticker.FormatStrFormatter(\"%g\"))\n",
    "ax.yaxis.set_minor_formatter(ticker.FormatStrFormatter(\"%g\"))\n",
    "\n",
    "# Add AB magnitudes as secondary x-axis at right\n",
    "# (Note this breaks if any fluxes are negative)\n",
    "# https://matplotlib.org/gallery/subplots_axes_and_figures/secondary_axis.html#sphx-glr-gallery-subplots-axes-and-figures-secondary-axis-py\n",
    "\n",
    "def AB2nJy(mAB):\n",
    "    m = mAB * u.ABmag\n",
    "    f = m.to(u.nJy)\n",
    "    return f.value\n",
    "\n",
    "def nJy2AB(F_nJy):\n",
    "    f = F_nJy * u.nJy\n",
    "    m = f.to(u.ABmag)\n",
    "    return m.value\n",
    "\n",
    "# secondary_axis = add_magnitude_axis(ax, flux_units)\n",
    "secax = ax.secondary_yaxis('right', functions=(nJy2AB, AB2nJy))\n",
    "secax.set_ylabel('magnitude (AB)')\n",
    "secax.yaxis.set_major_formatter(ticker.FormatStrFormatter(\"%g\"))\n",
    "secax.yaxis.set_minor_formatter(ticker.FormatStrFormatter(\"%g\"))\n",
    "\n",
    "plt.legend()\n",
    "plt.title('JADES SED PSF-corrected')\n",
    "# plt.savefig('JADES photutils SED.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
